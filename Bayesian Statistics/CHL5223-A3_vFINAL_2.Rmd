---
title: "CHL5223 - Applied Bayesian Methods - Assignment 3"
author: "Luis Correia - Student No. 1006508566"
date: "March 20th 2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
  rmarkdown::pdf_document:
    fig_caption: yes
    number_sections: yes
header-includes:
- \usepackage[margin=1in]{geometry} 
- \usepackage{amsmath,amsthm,amssymb,amsfonts}
- \usepackage{relsize}
- \usepackage{lscape}
- \usepackage{enumerate}
- \usepackage{enumitem}
- \usepackage{setspace}
- \usepackage{tikz}
- \usepackage{bm}
- \usepackage{bbm}
- \usepackage[utf8]{inputenc}
- \usepackage{mathtools, nccmath}
- \usepackage{fancyhdr}
- \usepackage{float}
- \usepackage{algorithm2e}
- \floatplacement{figure}{H}
- \floatplacement{table}{H}
- \pagestyle{fancy}
- \fancyhead[CO,CE]{---CHL5223 - Applied Bayesian Methods---}
- \fancyfoot[C]{Luis Correia - Student No. 1006508566}
- \fancyfoot[RO, LE] {\thepage}
- \setlength{\parskip}{1em}
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, fig.width=5, fig.height=4.0)
```

```{r, warning=FALSE, echo=FALSE}
library(tidyverse)
library(R2OpenBUGS)
library(kableExtra)
```

```{r}
library(ggplot2)
library(forecast)
library(coda)
# library(boa)

# The palette with black - Used in Graphs with :
cbp1 <- c("#999999", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbp2 <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbp3 <- c("#FFDB6D", "#C4961A", "#F4EDCA", "#D16103", 
          "#C3D7A4", "#52854C", "#4E84C4", "#293352")
```


\maketitle

\section{Question 1}

In the file "SmokeHyperHwkQuesR.txt", there is a preliminary analysis of a data-set. The analysis looks at the relationship between smoking and hypertension. For the population under study, there are a series of binary variables that are recorded. They record the following traits: smoker, obesity, snoring, gender as well as the outcome of interest which is hypertension. A table is created where the number of people with hypertension is recorded as well as the total number in that category.

(Aside: there were was no one who was a a smoker and obese who did not snore. So that group is not included in the table.) Also, note in that file, there is a basic analysis of this data. Starting with the analysis in this file, run the MCMC with more iterations and see if the chain has "converged". For the purpose of this exercise, just look at three parameters. Use either "sd.b" or "tau.b" for one of the parameters and use one of the "beta" parameters for the other two. Fit this model with either WinBugs, OpenBugs, or Jags (and provide the model in your answer.) Run the iteration with at least three chains in this model. Do the following:

\subsection{item (a)}

Run between $10,000$ to $30,000$ iterations of the MCMC. For the three parameters, provide a copy of the trace plot for a portion of the iteration, the auto-correlation plot, and the statistics.

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

For this item, we will run the model with \textit{no-burnin} and \textit{no-thin}, i.e.:

\begin{itemize}
    \item \underline{Run-0}: \texttt{n.iter}$=30,000$ with \texttt{n.burnin}$=0$ and \texttt{n.thin}$=1$ (every sample will be stored);
\end{itemize}

```{r}
#
#data from Healy, page 90.
#  (MJR Healy, 1988, Glim: An Introduction, Clarendon Press: Oxford.)
#  Looking to see if Smoking is a risk factor for hypertension, controlling for obesity, snoring, and gender
#  Note 1: there was no males or females who were smokers and obese and who did not snore (so 1 1 0 had no exposures)
#  Note 2: here we are simply looking at the effect of smoking given the other factors.  We are ignoring the possibility that 
#  obesity might be related to smoking or that snoring might be strongly effected by smoking and obesity.  
#  In modern epi, these factors might be consider to be in the <<causal path>> and perhaps you might not control for them in this way.
cat(
"smoke  obese  snore male hypoten n
0 0 0 1 5 60
0 0 0 0 10 149
1 0 0 1 2 17
1 0 0 0 6 16
0 1 0 1 1 12
0 1 0 0 2 9
0 0 1 1 36 187
0 0 1 0 28 138
1 0 1 1 13 85
1 0 1 0 4 39
0 1 1 1 15 51
0 1 1 0 11 28
1 1 1 1 8 23
1 1 1 0 4 12
", file= "Data/SmokeHyperData.txt")

```


```{r}
# Setup Data-set - Read Data
SmokeHyper=read.table("Data/SmokeHyperData.txt",header=TRUE,sep = "")

# Setup Variables
N=nrow(SmokeHyper)  # Number of Items in data-set

# Setup OpenBugs running parameters
NSim <- 30000    # No. of simulations for productio
NChain <- 3      # No. of chains for production
NThin <- 50      # n.thin parameter for production
Burnin <- 10000  # Burn-In parameter for production
Sz <- 5000       # Size of samples for trace/acf plots

```


```{r}
# Printing the Data-Frame
SmokeHyper %>%
  kbl(booktabs = TRUE, digits = 4,
      caption = "Data - Relationship between Hypertension and Smoking") %>% 
  kable_styling(latex_options = "striped")
 
```


```{r}
cat("
model{
  for(i in 1:N){
   hypoten[i] ~ dbin(mu[i], n[i])
   logit(mu[i]) <- b0 + b.smok*smoke[i]+ b.ob*obese[i]+ b.sn*snore[i] + 
     b.male*male[i] + b.smsn*smoke[i]*snore[i] + b[i]
    b[i] ~dnorm(0, tau.b)
   }
  b.smok ~ dnorm(0, .04) # so, sd =5.  exp(5) ~ 148 which is huge
  b.ob ~ dnorm(0, .04) 
  b.sn ~ dnorm(0, .04) 
  b.male ~ dnorm(0, .04) 
  b0 ~ dnorm(0, .04) 
  b.smsn ~dnorm(0, .04)
  sd.b ~ dunif(0, 5)
  tau.b <- 1/pow(sd.b,2)
  }
  ", file="SmokeHyperMod3.txt")

# Setup Parameters
paramsM0=c("b0", "b.smok", "b.ob", "b.sn", "b.male", "b.smsn" , "sd.b")

bugM0.dat=list("hypoten", "n", "smoke", "obese", "snore", "male", "N")  # what variable you need in the model

```

```{r}
# Setup Initial Values
initM0.fun=function(){ list(  b=runif(N,-.8,-.2), 
                              b0=runif(1,-.8,-.2),
                              b.smok=runif(1,-.8,-.2),b.ob=runif(1,-.8,-.2), b.sn=runif(1,-.8,-.2),
                              b.male=runif(1,-.8,-.2), b.smsn=runif(1, -8,-.2), sd.b=runif(1,.2,.8)	
) }

```

```{r, cache=TRUE}
#### Could change the code below...
# Run Open Bugs - NO BURNIN / NO THINN
set.seed(2602)
attach(SmokeHyper)
SmokeHypeBaseM0=bugs(bugM0.dat, initM0.fun, paramsM0, model.file="SmokeHyperMod3.txt",
    n.chains=NChain, n.iter=NSim, n.burnin=0, n.thin=1, debug=FALSE)
detach(SmokeHyper)

```


```{r}
# Get Simulation from OpenBugs
SArrayM0= SmokeHypeBaseM0$sims.array   # Data Arrays
vname=attr(SArrayM0,"dimnames")[3][[1]]  # Variable Names

```

```{r}
# Print Summary statistics of parameters oif Interest
RNames <- rownames(SmokeHypeBaseM0[["summary"]][,c(1:3,5,7)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(SmokeHypeBaseM0[["summary"]][,c(1:3,5,7)]))
df_Prt %>%
  kbl(booktabs = TRUE, digits = 4, 
      caption = "OpenBugs Summary - Hypertension and Smoke Study (Run-0)") %>% 
  kable_styling(latex_options = "striped")
```

For this question we will generate \textit{no-thinned} trace and ACF plots of parameter estimates for $\sigma$, $\beta_0$, $\beta_{Smoke}$ and $\beta_{Obesity}$ to assess its \textit{convergence} and possible existence of auto-correlation in sampled data contains. 

For the sake of simplicity, ACF plots will contain only chain \#1 in order to avoid deteriorating the PDF's performance with uninformative data, since the results are quite similar for all chains.

Please also note that it was used the \texttt{ggAcf()} function from package \texttt{forecast} due to its flexibility and configuration capabilities. The main difference of it from the standard \texttt{acf} is that \texttt{ggAcf()} starts plotting from $lag=1$, and \texttt{acf()} starts at $lag=0$. 

```{r, fig.cap= "Trace-plots of $\\sigma$, $\\beta_0$, $\\beta_{Smoke}$ and $\\beta_{Obesity}$ (Run-0)", fig.height=3.5, fig.width=4.5}
# Plot TracePlots * SIGMA, BETA0, BETA.SMOKE and BETA.OBESITY *

# Sampling 5000 points to generate "thinner" traceplots
set.seed(312)

L <- NSim-Burnin

OldSz <- Sz  
Sz <- L       # Override Original value

S <- if (Sz < L) sort(sample(1:L, Sz, replace = FALSE)) else 1:Sz
 
# Build working dataframe
D_WorkSigma <- data.frame(ValCh1=SArrayM0[S,1,paste0("sd.b")],
                          ValCh2=SArrayM0[S,2,paste0("sd.b")],
                          ValCh3=SArrayM0[S,3,paste0("sd.b")])

D_WorkBeta0 <- data.frame(ValCh1=SArrayM0[S,1,paste0("b0")],
                          ValCh2=SArrayM0[S,2,paste0("b0")],
                          ValCh3=SArrayM0[S,3,paste0("b0")])

D_WorkBetaSmok <- data.frame(ValCh1=SArrayM0[S,1,paste0("b.smok")],
                             ValCh2=SArrayM0[S,2,paste0("b.smok")],
                             ValCh3=SArrayM0[S,3,paste0("b.smok")])

D_WorkBetaObes <- data.frame(ValCh1=SArrayM0[S,1,paste0("b.ob")],
                             ValCh2=SArrayM0[S,2,paste0("b.ob")],
                             ValCh3=SArrayM0[S,3,paste0("b.ob")])

# Plot Traceplots for selected data-frames
P1 <- D_WorkSigma %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(sigma)) +
        theme_bw()
P2 <- D_WorkBeta0 %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta[0])) +
        theme_bw()
P3 <- D_WorkBetaSmok %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta[Smoke])) +
        theme_bw()
P4 <- D_WorkBetaObes %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta[Obesity])) +
        theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"), 
                  P2+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"),
                  P3+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"),
                  P4+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"), ncol = 2, nrow = 2)

# Remove Working Variable to free memory
Sz <- OldSz # Restore original value
remove(OldSz, D_WorkSigma, D_WorkBeta0, D_WorkBetaSmok, D_WorkBetaObes )
```

\textbf{Comment}:- From Trace Plots we can verify that parameters estimates for $\sigma$, $\beta_0$, $\beta_{Smoke}$ and $\beta_{Obesity}$ generated by our simulations \textit{converged} after a few iterations. We can also observe a peak in the early simulations due to stabilization of Markov Chain as we are not using \textit{burnin} parameters for \textbf{Run-0}.

```{r, fig.cap= "ACF-plots of $\\sigma$, $\\beta_0$, $\\beta_{Smoke}$ and $\\beta_{Obesity}$ (max-Lag=100) (Run-0)"}
# Plot ACF Plots * SIGMA, BETA0, BETA.SMOKE and BETA.OBESITY *

# Build working dataframe
D_WorkSigma <- data.frame(ValCh1=SArrayM0[,1,paste0("sd.b")])
D_WorkBeta0 <- data.frame(ValCh1=SArrayM0[,1,paste0("b0")])
D_WorkBetaSmok <- data.frame(ValCh1=SArrayM0[,1,paste0("b.smok")])
D_WorkBetaObes <- data.frame(ValCh1=SArrayM0[,1,paste0("b.ob")])

# Plot ACF Plots for selected data-frames
P1 <- ggAcf(D_WorkSigma$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(sigma)) +
  ggtitle(NULL)+
  theme_bw()
P2 <- ggAcf(D_WorkBeta0$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta[0])) +
  ggtitle(NULL)+
  theme_bw()
P3 <- ggAcf(D_WorkBetaSmok$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta[Smoke])) +
  ggtitle(NULL)+
  theme_bw()
P4 <- ggAcf(D_WorkBetaObes$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta[Obesity])) +
  ggtitle(NULL)+
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)
# Remove Working Variable to free memory
remove(D_WorkSigma, D_WorkBeta0, D_WorkBetaSmok, D_WorkBetaObes )
```

\textbf{Comment}:- From ACF Plots we can also verify the parameters estimates generated by our simulations are \textit{highly correlated} for all parameters in the early stages of the simulation, approximately up to \texttt{lag=$100$} (e.g., parameter $\sigma$). This is due to MCMC simulations carry some auto-correlation between samples by construction of Gibbs Sampler and also because we are not using the \texttt{n.thin} parameter to discard consecutive samples.

\subsection{item (b)}

Input the MCMC values into R (but not yet into coda). Plot the trace plot in R. Remove some of the early values of the chain (throwing away a part that is "burned-in") and then plot the estimate of the densities for the parameters with a different density estimate for each of the three chains. What effect does "burning in" the chain have?

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

In this item we will use the results of \textbf{Run-01}, i.e., simulations generated with \texttt{n.burnin}$=10,000$ and \texttt{n.thin}$=50$ (every 50-th value sampled will be maintained).

```{r}
# Setup Parameters for Run-01

paramsM1 <- paramsM0

bugM1.dat <- bugM0.dat

initM1.fun <- initM0.fun

```

```{r, cache=TRUE}
# Run Open Bugs - BURNIN=10,000 / THINN=50
set.seed(2212)
attach(SmokeHyper)
SmokeHypeBaseM1=bugs(bugM1.dat, initM1.fun, paramsM1, model.file="SmokeHyperMod3.txt",
    n.chains=NChain, n.iter=NSim, n.burnin=Burnin, n.thin=NThin , debug=FALSE)
detach(SmokeHyper)

```

```{r}
# Get Simulation from OpenBugs
SArrayM1= SmokeHypeBaseM1$sims.array   # Data Arrays
vname=attr(SArrayM1,"dimnames")[3][[1]]  # Variable Names

```


```{r}
# Print Summary statistics of parameters oif Interest
RNames <- rownames(SmokeHypeBaseM1[["summary"]][,c(1:3,5,7)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(SmokeHypeBaseM1[["summary"]][,c(1:3,5,7)]))
df_Prt %>%
  kbl(booktabs = TRUE, digits = 4, 
      caption = "OpenBugs Summary - Hypertension and Smoke Study (Run-1)") %>% 
  kable_styling(latex_options = "striped")
```

```{r, fig.cap= "Trace-plots of $\\sigma$, $\\beta_0$, $\\beta_{Smoke}$ and $\\beta_{Obesity}$", fig.height=3.5, fig.width=4.5}
# Plot TracePlots * SIGMA, BETA0, BETA.SMOKE and BETA.OBESITY *

# Sampling 5000 points to generate "thinner" traceplots
set.seed(312)

L <- NSim-Burnin

OldSz <- Sz  
Sz <- L       # Override Original value

S <- if (Sz < L) sort(sample(1:L, Sz, replace = FALSE)) else 1:Sz
 
# Build working dataframe
D_WorkSigma <- data.frame(ValCh1=SArrayM1[S,1,paste0("sd.b")],
                          ValCh2=SArrayM1[S,2,paste0("sd.b")],
                          ValCh3=SArrayM1[S,3,paste0("sd.b")])

D_WorkBeta0 <- data.frame(ValCh1=SArrayM1[S,1,paste0("b0")],
                          ValCh2=SArrayM1[S,2,paste0("b0")],
                          ValCh3=SArrayM1[S,3,paste0("b0")])

D_WorkBetaSmok <- data.frame(ValCh1=SArrayM1[S,1,paste0("b.smok")],
                             ValCh2=SArrayM1[S,2,paste0("b.smok")],
                             ValCh3=SArrayM1[S,3,paste0("b.smok")])

D_WorkBetaObes <- data.frame(ValCh1=SArrayM1[S,1,paste0("b.ob")],
                             ValCh2=SArrayM1[S,2,paste0("b.ob")],
                             ValCh3=SArrayM1[S,3,paste0("b.ob")])

# Plot Traceplots for selected data-frames
P1 <- D_WorkSigma %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(sigma)) +
        theme_bw()
P2 <- D_WorkBeta0 %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta[0])) +
        theme_bw()
P3 <- D_WorkBetaSmok %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta[Smoke])) +
        theme_bw()
P4 <- D_WorkBetaObes %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta[Obesity])) +
        theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"), 
                  P2+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"),
                  P3+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"),
                  P4+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"), ncol = 2, nrow = 2)

# Remove Working Variable to free memory
Sz <- OldSz # Restore original value
remove(OldSz, D_WorkSigma, D_WorkBeta0, D_WorkBetaSmok, D_WorkBetaObes )
```

\textbf{Comment}:- From Trace Plots for \textbf{Run-1} we can verify that parameters estimates for $\sigma$, $\beta_0$, $\beta_{Smoke}$ and $\beta_{Obesity}$ generated by our simulations have chains well mixed and all \textit{converged}.

We can notice the effect of \textit{burnin} when we compare the above trace-plots with the ones obtained on \underline{Run-0}: the stabilization of chains were in the very early iterations in \underline{Run-1} while in  \underline{Run-0} we had to run a few iterations before the samples stabilizes.

```{r, fig.cap= "ACF-plots of $\\sigma$, $\\beta_0$, $\\beta_{Smoke}$ and $\\beta_{Obesity}$ (max-Lag=100)"}
# Plot ACF Plots * SIGMA, BETA0, BETA.SMOKE and BETA.OBESITY *

# Build working dataframe
D_WorkSigma <- data.frame(ValCh1=SArrayM1[,1,paste0("sd.b")])
D_WorkBeta0 <- data.frame(ValCh1=SArrayM1[,1,paste0("b0")])
D_WorkBetaSmok <- data.frame(ValCh1=SArrayM1[,1,paste0("b.smok")])
D_WorkBetaObes <- data.frame(ValCh1=SArrayM1[,1,paste0("b.ob")])

# Plot ACF Plots for selected data-frames
P1 <- ggAcf(D_WorkSigma$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(sigma)) +
  ggtitle(NULL)+
  theme_bw()
P2 <- ggAcf(D_WorkBeta0$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta[0])) +
  ggtitle(NULL)+
  theme_bw()
P3 <- ggAcf(D_WorkBetaSmok$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta[Smoke])) +
  ggtitle(NULL)+
  theme_bw()
P4 <- ggAcf(D_WorkBetaObes$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta[Obesity])) +
  ggtitle(NULL)+
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)
# Remove Working Variable to free memory
remove(D_WorkSigma, D_WorkBeta0, D_WorkBetaSmok, D_WorkBetaObes )
```

\textbf{Comment}:- Differently from \textbf{Run-0}, ACF Plots from \textbf{Run-1} have small auto-correlation between estimates concentrated in initial lags and all apparently become uncorrelated after \texttt{lag=$5$}. Thinning the MCMC simulations contributed to generate less auto-correlated samples.

\medskip

\subsection{item (c)}

If you thinned the chain, what would be the advantages? Is it necessary to thin a chain?

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

In practice, when we generate samples through MCMC (Markov Chain Monte Carlo) algorithms, we need to make all efforts possible to have the convergence achieved. In this sense, when we stop a Markov chain at a finite number of iterations, we don't obtain independent realizations as each estimate is generated from the previous ones. On the other hand, as the chain estimates advances, such dependence will decrease and, in the limit, we will have independent realizations from the posterior distribution.

\textit{Thinning} a Markov Chain consists in picking separated points from the sample, at each \textit{k-th} step. The major advantage of this process is to separate the points sampled by the Markov Chain to reduce auto-correlation between observations. By doing this we will obtain some level of independent samples at the end-game. 

In our case, it was used \texttt{n.thin=50} for \textit{Run-1} and we have obtained quite good results in terms of convergence and \textit{less}-auto-correlated samples.

Another technical advantage of specifying a thinning parameter is because when the number of parameters is large, thinning helps obtain the saved output of our model to a reasonably-sized R object.

\medskip

\subsection{item (d)}

Provide the estimate of the posterior mean of the three parameters for each chain and also give the Monte Carlo accuracy of your estimate. For the Monte Carlo accuracy, compute by batch means and by using the auto-correlation function.

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

```{r}
# Prepare data to plot densities to Compare Distributions of 
# * SIGMA, BETA0, BETA.SMOKE and BETA.OBESITY *

set.seed(9023)

L <- NSim-Burnin

S <- if (Sz < L) sort(sample(1:L, Sz, replace = FALSE)) else 1:Sz

# Build working dataframe
D_WorkSigma <- as_tibble(rbind(data.frame(LvlStd=as.vector(SArrayM1[S,1,paste0("sd.b")]), Chain = "C1"),
                               data.frame(LvlStd=as.vector(SArrayM1[S,2,paste0("sd.b")]), Chain = "C2"),
                               data.frame(LvlStd=as.vector(SArrayM1[S,3,paste0("sd.b")]), Chain = "C3")))
D_WorkBeta0 <- as_tibble(rbind(data.frame(LvlStd=as.vector(SArrayM1[S,1,paste0("b0")]), Chain = "C1"),
                               data.frame(LvlStd=as.vector(SArrayM1[S,2,paste0("b0")]), Chain = "C2"),
                               data.frame(LvlStd=as.vector(SArrayM1[S,3,paste0("b0")]), Chain = "C3")))
D_WorkBetaSmok <- as_tibble(rbind(data.frame(LvlStd=as.vector(SArrayM1[S,1,paste0("b.smok")]), Chain = "C1"),
                                  data.frame(LvlStd=as.vector(SArrayM1[S,2,paste0("b.smok")]), Chain = "C2"),
                                  data.frame(LvlStd=as.vector(SArrayM1[S,3,paste0("b.smok")]), Chain = "C3")))
D_WorkBetaObes <- as_tibble(rbind(data.frame(LvlStd=as.vector(SArrayM1[S,1,paste0("b.ob")]), Chain = "C1"),
                                  data.frame(LvlStd=as.vector(SArrayM1[S,2,paste0("b.ob")]), Chain = "C2"),
                                  data.frame(LvlStd=as.vector(SArrayM1[S,3,paste0("b.ob")]), Chain = "C3")))
```


```{r}
# Calculates Batch Means and respective SE - Author: Michael Escobar (thank you!)
CalcBatchMeans <- function (x, Batn = 50) {
  BigN=length(x)
  BatInc=ceiling((1:BigN)/(BigN/Batn) )
  BM=tapply(x,BatInc,mean)
  return(list(MCE=(sd(BM)/sqrt(length(BM))), BM=BM))
}

# Calculates the Standard Error via Auto-Correlation Function - Author: Michael Escobar (thank you!)
CalcAcSe=function(x,lag.max=50){
  autoc=(acf(x,lag.max=lag.max,plot=FALSE))$acf
  sd(x)/sqrt(length(x))*sqrt(-1+2*sum(autoc))
}

CalcChainStats <- function (parm, chain, TxtParm) {
  L <- CalcBatchMeans(SArrayM1[,chain,paste0(parm)])
  S <- CalcAcSe(SArrayM1[,chain,paste0(parm)],120)
  cat("\n---- Summary Statistics for",TxtParm,"(Chain ",chain,") -----")
  cat("\nB-Mean : ",format(mean(L$BM), digits = 2, nsmall = 4)) 
  cat("\nB-S.E.: ",format(L$MCE, digits = 2, nsmall = 6))
  CI_up <- mean(L$BM)+2*L$MCE; CI_lo <- mean(L$BM)-2*L$MCE; 
  cat("\n95% Credible Region (", 
      format(CI_lo, digits = 2, nsmall = 4), ",",
      format(CI_up, digits = 2, nsmall = 4),")\n")
  cat("\n(ACF) S.E.: ",format(S, digits = 2, nsmall = 6))
  CI_up <- mean(L$BM)+2*S; CI_lo <- mean(L$BM)-2*S; 
  cat("\n(ACF) 95% Credible Region (", 
      format(CI_lo, digits = 2, nsmall = 4), ",",
      format(CI_up, digits = 2, nsmall = 4),")\n")
  cat("---------------------------------------------------\n")
}
```

We calculated posterior means for the parameters using \textit{Batch-Means} procedure, including \textit{Batch-Standard Error} and \textit{ACF Standard Error}. We also plotted the posterior densities of each parameter.

The results are shown below. 

\subsubsection{Parameter $\sigma$}

```{r}
# Calculates Posterior Means using Batch-Means and ACF - SIGMA
CalcChainStats("sd.b",1,"SIGMA")
CalcChainStats("sd.b",2,"SIGMA")
CalcChainStats("sd.b",3,"SIGMA")
```

```{r,fig.cap= "Posterior Distributions of $\\sigma$", fig.width=4.5, fig.height=3.5}
D_WorkSigma %>%
  ggplot(aes(x = LvlStd))+
  geom_density(aes(x=LvlStd, group=Chain, colour=Chain), size=0.8)+ 
  labs(x = expression(sigma), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()
```


\subsubsection{Parameter $\beta_0$}

```{r}
# Calculates Posterior Means using Batch-Means and ACF - BETA0
CalcChainStats("b0",1,"BETA0")
CalcChainStats("b0",2,"BETA0")
CalcChainStats("b0",3,"BETA0")

```

```{r,fig.cap= "Posterior Distributions of $\\beta_0$", fig.width=4.5, fig.height=3.5}
D_WorkBeta0 %>%
  ggplot(aes(x = LvlStd))+
  geom_density(aes(x=LvlStd, group=Chain, colour=Chain), size=0.8)+ 
  labs(x = expression(beta[0]), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()
```


\subsubsection{Parameter $\beta_{Smoke}$}

```{r}
# Calculates Posterior Means using Batch-Means and ACF - BETA-SMOKE
CalcChainStats("b.smok",1,"BETA-SMOKE")
CalcChainStats("b.smok",2,"BETA-SMOKE")
CalcChainStats("b.smok",3,"BETA-SMOKE")


```

```{r,fig.cap= "Posterior Distributions of $\\beta_{Smoke}$", fig.width=4.5, fig.height=3.5}
D_WorkBetaSmok %>%
  ggplot(aes(x = LvlStd))+
  geom_density(aes(x=LvlStd, group=Chain, colour=Chain), size=0.8)+ 
  labs(x = expression(beta[Smoke]), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()
```


\subsubsection{Parameter $\beta_{Obesity}$}

```{r}
# Calculates Posterior Means using Batch-Means and ACF - BETA-OBESITY
CalcChainStats("b.ob",1,"BETA-OBESITY")
CalcChainStats("b.ob",2,"BETA-OBESITY")
CalcChainStats("b.ob",3,"BETA-OBESITY")

```

```{r,fig.cap= "Posterior Distributions of $\\beta_{Obesity}$", fig.width=4.5, fig.height=3.5}
D_WorkBetaObes %>%
  ggplot(aes(x = LvlStd))+
  geom_density(aes(x=LvlStd, group=Chain, colour=Chain), size=0.8)+ 
  labs(x = expression(beta[Obesity]), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()
```


\underline{Comment}:- Batch-means statistics are close in all chains of its own parameter. We also can see the Batch and ACF-Standard Errors and are small and close to each other, also reinforcing our belief of convergence, which can also be seen through the $95\%$ Credible Regions obtained and the respective posterior densities, as well.

```{r}
# Remove Working Variables and workdataframes used in this question to free memory
remove(D_WorkSigma, D_WorkBeta0, D_WorkBetaSmok, D_WorkBetaObes )
```

\bigskip

\subsection{item (e)}

Using the coda (or boa) package, use the \textit{Geweke} and \textit{Brooks-Gelman-Rubin} diagnostic procedures to assess how well the MCMC algorithm has converged.

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

Using the \texttt{coda} package we obtained the Geweke and Brooks-Gelman-Rubin diagnostics for our estimates. We also plotted the useful \texttt{geweke.plot()} and \texttt{gelman.plot()} to verify convergence and stabilization of simulated chains for our parameters. The results are shown below:

```{r}
# Prepare Structures for CODA
Chn.sigma <- list( C1=mcmc(SArrayM1[,1,paste0("sd.b")]),
                   C2=mcmc(SArrayM1[,2,paste0("sd.b")]),
                   C3=mcmc(SArrayM1[,3,paste0("sd.b")]))
Chn.b0 <- list( C1=mcmc(SArrayM1[,1,paste0("b0")]),
                C2=mcmc(SArrayM1[,2,paste0("b0")]),
                C3=mcmc(SArrayM1[,3,paste0("b0")]))
Chn.bsmok <- list( C1=mcmc(SArrayM1[,1,paste0("b.smok")]),
                   C2=mcmc(SArrayM1[,2,paste0("b.smok")]),
                   C3=mcmc(SArrayM1[,3,paste0("b.smok")]))
Chn.bob <- list( C1=mcmc(SArrayM1[,1,paste0("b.ob")]),
                 C2=mcmc(SArrayM1[,2,paste0("b.ob")]),
                 C3=mcmc(SArrayM1[,3,paste0("b.ob")]))
```


```{r}
# Calculate Summary MCMC of estimates
CalcDiags <- function (MC, TxtParm) {
  MMC <- cbind(MC$C1,MC$C2,MC$C3)
  colnames(MMC) <- c("Chain1","Chain2","Chain3")
  cat("\n--------- CODA Summary Statistics for",TxtParm,"---------\n")
  print(summary(mcmc(MMC)))
  cat(">>> Effective Size:\n")
  print(effectiveSize(MMC))
  cat("\n>>> GEWEKE Diagnostics:")
  print(geweke.diag(MMC))
  geweke.plot(mcmc(MMC))
  cat(">>> GELMAN Diagnostics:\n")
  print(gelman.diag(MC))
  gelman.plot(MC)
}

```


\subsubsection{Parameter $\sigma$}

```{r}
CalcDiags(Chn.sigma, "SIGMA")
```

\subsubsection{Parameter $\beta_0$}

```{r}
CalcDiags(Chn.b0, "BETA-0")
```

\subsubsection{Parameter $\beta_{Smoke}$}

```{r}
CalcDiags(Chn.bsmok, "BETA-SMOKE")
```

\subsubsection{Parameter $\beta_{Obesity}$}

```{r}
CalcDiags(Chn.bob, "BETA-OBESITY")
```

\subsection{item (f)}

Using the information from this question, state if you feel that the MCMC algorithm has converged. Justify your answer.

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

\textit{Geweke} diagnostics applies a simple Z-test to check whether the means estimated from two different sub-samples of the total MCMC output are equal, in particular, the default parameters are the initial $10\%$ and the last $50\%$ of the total iterations. It can be demonstrated\footnote{See \cite{Ntzoufras}.} that the statistic \textit{Z} provided by the diagnostic asymptotically follows the standardized normal distribution. Values that lie in its tails provide an indication of non-convergence. 

In our case, all Z-scores provided to all chains of the parameters of interest have fallen into the interval $\pm 1.96$ in Geweke Diagnostics. This result provides no evidence of lack of convergence of MCMC Algorithm. 

This can be also seen in \textit{Geweke Plots} where every batch lie inside the $95\%$ confidence interval, i.e.,$\pm2*SE$ which reinforces the no evidence of lack of convergence.

In same way, we obtained values near or equal to $1.0$ in \textit{Gelman Diagnostics}, which means there is no indication that the chains have not converged in \textit{Run-1} model.  

\textit{Gelman Plots} shows in what iteration the chains approximately stabilizes. 

We can conclude the parameter $\texttt{n.burnin}=10,000$ reduced the fluctuation of all chains to an acceptable scale-reduction over time\footnote{We noticed some fluctuation at the beginning of each chain but there is no evidence they have not  converged.}.

\pagebreak

\section{Question 2}

Consider the following data which contains information on harvesting dates versus crop yields. The \textbf{x} variable is data on date of harvesting (which is the number of days after flowering) and yield \textbf{y} (kg/ha) of paddy, a grain farmed in India. (Data from Devore pg 518 and originally from \textit{J. Agricultural Eng. Research}, 1975, pp 353-363.)

Here is the data:

\texttt{list(x=c(16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46), y=c(2508, 2518, 3304, 3423, 3057, 3190, 3500, 3883, 3823, 3646, 3708, 3333, 3517, 3241, 3103, 2776))}

Consider two models for this data. The first model predicts the population as a linear function of the date and the second predicts with a quadratic function. The following WinBugs/OpenBugs code will fit these models (This information is in a txt file that is sent with this file. You can get the the data and model codes from that file and you won't have to type them in):

Consider two models for this data.  The first model predicts the population as a linear function of the date and the second predicts with a quadratic function.  The following WinBugs code will fit these models (This information is in a txt file that is sent with this file.  You can get the the data and model codes from that file and you won't have to type them in):

Model 1:

\begin{verbatim}
model{
for(i in 1:16){
  y[i]~dnorm(mu[i],tau)
  mu[i]<- b[1] + b[2]*(x[i]-31)
}
b[1]~dnorm(0,.000001)
b[2]~dnorm(0,.000001)
tau~dgamma(.0001,.0001)
}
\end{verbatim}

Model 2:

\begin{verbatim}
model{
for(i in 1:16){
  y[i]~dnorm(mu[i],tau)
  mu[i]<- b[1] + b[2]*(x[i]-31)+b[3]*pow((x[i]-31),2)
}
b[1]~dnorm(0,.000001)
b[2]~dnorm(0,.000001)
b[3]~dnorm(0,.01)
tau~dgamma(.0001,.0001)
}
\end{verbatim}

Do the following two parts:

\subsection{item (a)}

Compare these two models. First, compare these two models by looking at the "deviance" measures and the DIC. Calculate these values for each model and comment on them. Then, compare these two models by calculating the Bayes Factor. To calculate the Bayes factor, run an MCMC algorithm which switches between the two models using a method similar (in which you might have to somewhat change the model code as well as the model) to the method proposed by Kuo and Mallick. Comment on your belief between the two models. (That is, which model do you prefer and justify your answer.)

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

```{r}
# Setup Data-set - Read Data
HarvestingData <- data.frame( x=c(16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46),
y=c(2508,2518,3304,3423,3057,3190,3500,3883,3823,3646,3708,
3333,3517,3241,3103,2776))

# Setup Variables
N=nrow(HarvestingData)  # Number of Items in data-set

# Setup OpenBugs running parameters
NSim <- 30000    # No. of simulations for productio
NChain <- 3      # No. of chains for production
NThin <- 10      # n.thin parameter for production
Burnin <- 10000  # Burn-In parameter for production
Sz <- 5000       # Size of samples for trace/acf plots

```

The data of our problem is presented in table below.

```{r}
# Printing the Data-Frame
HarvestingData %>%
  kbl(booktabs = TRUE, digits = 1,
      caption = "(x):Harvesting Date (in days) vs. (y):Yield (in Kg/Ha)") %>% 
  kable_styling(latex_options = "striped")
 
```

```{r, fig.cap= "Scatterplot Harvesting Data - X vs. Y", fig.width=4.0, fig.height=3.0}
HarvestingData %>%
  ggplot(aes(x=x, y=y))+
  geom_point(size=2.5)+ 
  labs(x = "X (# of days after flowering)", y = "Y (Yield in Kg/ha)") +
  theme_bw()
```



```{r}
# MODEL Q2_1
cat("### Model 1 -
model{
  for (i in 1:N) {
    y[i]~dnorm(mu[i],tau)
    mu[i]<- b[1] + b[2]*(x[i]-31)
 
    # Get the residuals for the observed value
    res[i] <- (y[i]-mu[i])           # Estimate the residual for this model  - Item (1)
    stdres[i] <- res[i]*sqrt(tau)    # Calculate the standard residuals - Item (2)
    
    dev1.obs[i] <- pow(res[i],2)
    dev2.obs[i] <- pow(stdres[i],2)
    
    # Get a replicated Sample - sample of the predictive distribution
    y.rep[i]~dnorm(mu[i],tau)
    p.smaller[i] <- step(y[i]-y.rep[i])  # Check to see the probability of getting extreme value - Item (3)
    
    # Residual and Moments replicated - this gives the predicted distribution for these values
    res.rep[i] <- y.rep[i]-mu[i]
    stdres.rep[i] <- res.rep[i]*sqrt(tau)
    
    dev1.rep[i] <- pow(res.rep[i],2)
    dev2.rep[i] <- pow(stdres.rep[i],2)
    
    # Likelihood for each observed and replicated data
    # note: Need to know the density function of the probability model
    
    loglike[i] <- (0.5)*log(tau/6.283185) + (-0.5)*tau*pow((y[i]-mu[i]),2)
    loglike.rep[i]<-  (0.5)*log(tau/6.283185) + (-0.5)*tau*pow((y.rep[i]-mu[i]),2)
    
    p.inv[i]<- 1/exp(loglike[i])      #  This is to find the predictive ordinate of the observations
  }
  
  # Prior definitions
  b[1]~dnorm(0,.000001)
  b[2]~dnorm(0,.000001)
  tau~dgamma(.0001,.0001)

  # Summing Diagnostics Values
  chidev1.obs <- sum(dev1.obs[])
  chidev2.obs <- sum(dev2.obs[])

  chidev1.rep <- sum(dev1.rep[] )
  chidev2.rep <- sum(dev2.rep[] )

  chidev1.pval<-step(chidev1.obs-chidev1.rep)
  chidev2.pval<-step(chidev2.obs-chidev2.rep)

  #   Deviance statistic
  dev<-   -2*sum(loglike[])
  dev.rep <-  -2*sum(loglike.rep[])
  dev.pval<-step(dev-dev.rep)

}", file="HarvestModQ21.txt")
  

# Setup Parameters
bugMQ21.dat<-list("x", "y", "N")

initMQ21.fun<-function(){ list(b=runif(2,-.8,-.2), tau=runif(1,.2,.8), y.rep=rnorm(N))} 

paramsMQ21<-c("b", "tau",          # the rest are for the model checking
              "mu", "res", "stdres", "res.rep", "stdres.rep", "p.smaller",
              "p.inv", "chidev1.pval", "chidev2.pval", "chidev1.obs", "chidev2.obs",
              "chidev1.rep", "chidev2.rep", "dev", "dev.rep", "dev.pval")

```


```{r, cache=TRUE}
#### Could change the code below...
# Run Open Bugs - 
set.seed(2157)
attach(HarvestingData)
HarvestingMQ21=bugs(bugMQ21.dat, initMQ21.fun, paramsMQ21, model.file="HarvestModQ21.txt",
    n.chains=NChain, n.iter=NSim, n.burnin=Burnin, n.thin=NThin)
detach(HarvestingData)

```

```{r}
# Get Simulation from OpenBugs
SArrayMQ21= HarvestingMQ21$sims.array   # Data Arrays
vname=attr(SArrayMQ21,"dimnames")[3][[1]]  # Variable Names
MQ21.coda <- as.mcmc.list(HarvestingMQ21)

```

For each Model, we simulated MCMC samples using \textit{OpenBugs} with parameters \texttt{n.iter}$=30,000$ iterations, \texttt{n.burnin}$=10,000$ and \texttt{n.thin}$=10$. The summary of results are as follows:

```{r}
# Print Summary statistics of parameters oif Interest
RNames <- rownames(HarvestingMQ21[["summary"]][,c(1:3,5,7)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(HarvestingMQ21[["summary"]][,c(1:3,5,7)]))
df_Prt %>%
  filter(substr(Parameter,1,2)=="b[" |
           substr(Parameter,1,3)=="tau") %>% 
  kbl(booktabs = TRUE, digits = 4,
      caption = "OpenBugs Summary - Harvesting Date vs. Yield (Model-1)") %>% 
  kable_styling(latex_options = "striped")
```

\medskip

\subsubsection{Checking Convergence and Auto-Correlation for Model-1}

```{r, fig.cap= "Trace-plots of $\\beta_1$, $\\beta_2$ and $\\tau$ for Model-1", fig.height=3.5, fig.width=4.5}
# Plot TracePlots * b[1], b[2] and tau *

# Sampling 5000 points to generate "thinner" traceplots
set.seed(312)

L <- NSim-Burnin

#OldSz <- Sz  
#Sz <- L       # Override Original value

S <- if (Sz < L) sort(sample(1:L, Sz, replace = FALSE)) else 1:Sz
 
# Build working dataframe
D_Workb1<- data.frame(ValCh1=SArrayMQ21[S,1,paste0("b[1]")],
                      ValCh2=SArrayMQ21[S,2,paste0("b[1]")],
                      ValCh3=SArrayMQ21[S,3,paste0("b[1]")])

D_Workb2 <- data.frame(ValCh1=SArrayMQ21[S,1,paste0("b[2]")],
                       ValCh2=SArrayMQ21[S,2,paste0("b[2]")],
                       ValCh3=SArrayMQ21[S,3,paste0("b[2]")])

D_Worktau <- data.frame(ValCh1=SArrayMQ21[S,1,paste0("tau")],
                        ValCh2=SArrayMQ21[S,2,paste0("tau")],
                        ValCh3=SArrayMQ21[S,3,paste0("tau")])

# Plot Traceplots for selected data-frames
P1 <- D_Workb1 %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta[1])) +
        theme_bw()
P2 <- D_Workb2 %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta[2])) +
        theme_bw()
P3 <- D_Worktau %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(tau)) +
        theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"), 
                  P2+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"),
                  P3+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"), ncol = 2, nrow = 2)

# Remove Working Variable to free memory
# Sz <- OldSz # Restore original value
remove(D_Workb1, D_Workb2, D_Worktau )
```

```{r, fig.cap= "ACF-plots of $\\beta_1$, $\\beta_2$ and $\\tau$ for Model-1 (max-Lag=50)"}
# Plot ACF Plots * b[1], b[2] and tau *

# Build working dataframe
D_Workb1 <- data.frame(ValCh1=SArrayMQ21[,1,paste0("b[1]")])
D_Workb2 <- data.frame(ValCh1=SArrayMQ21[,1,paste0("b[2]")])
D_Worktau <- data.frame(ValCh1=SArrayMQ21[,1,paste0("tau")])

# Plot ACF Plots for selected data-frames
P1 <- ggAcf(D_Workb1$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(beta[1])) +
  ggtitle(NULL)+
  theme_bw()
P2 <- ggAcf(D_Workb2$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(beta[2])) +
  ggtitle(NULL)+
  theme_bw()
P3 <- ggAcf(D_Worktau$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(tau)) +
  ggtitle(NULL)+
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)
# Remove Working Variable to free memory
remove(D_Workb1, D_Workb2, D_Worktau )
```

\underline{Comment}:- We can see from trace and ACF plots that we have \underline{no evidence} that our estimates have not converged or are auto-correlated for \textbf{Model-1}.

```{r}
# MODEL Q2_2
cat("### Model 2 -
model{
  for (i in 1:N) {
    y[i]~dnorm(mu[i],tau)
    mu[i]<- b[1] + b[2]*(x[i]-31)+ b[3]*pow((x[i]-31),2)
 
    # Get the residuals for the observed value
    res[i] <- (y[i]-mu[i])           # Estimate the residual for this model  - Item (1)
    stdres[i] <- res[i]*sqrt(tau)    # Calculate the standard residuals - Item (2)
    
    dev1.obs[i] <- pow(res[i],2)
    dev2.obs[i] <- pow(stdres[i],2)
    
    # Get a replicated Sample - sample of the predictive distribution
    y.rep[i]~dnorm(mu[i],tau)
    p.smaller[i] <- step(y[i]-y.rep[i])  # Check to see the probability of getting extreme value - Item (3)
    
    # Residual and Moments replicated - this gives the predicted distribution for these values
    res.rep[i] <- y.rep[i]-mu[i]
    stdres.rep[i] <- res.rep[i]*sqrt(tau)
    
    dev1.rep[i] <- pow(res.rep[i],2)
    dev2.rep[i] <- pow(stdres.rep[i],2)
    
    # Likelihood for each observed and replicated data
    # note: Need to know the density function of the probability model
    
    loglike[i] <- (0.5)*log(tau/6.283185) + (-0.5)*tau*pow((y[i]-mu[i]),2)
    loglike.rep[i]<-  (0.5)*log(tau/6.283185) + (-0.5)*tau*pow((y.rep[i]-mu[i]),2)
    
    p.inv[i]<- 1/exp(loglike[i])      #  This is to find the predictive ordinate of the observations
  }
  
  # Prior definitions
  b[1]~dnorm(0,.000001)
  b[2]~dnorm(0,.000001)
  b[3]~dnorm(0,.01)
  tau~dgamma(.0001,.0001)

  # Summing Diagnostics Values
  chidev1.obs <- sum(dev1.obs[])
  chidev2.obs <- sum(dev2.obs[])

  chidev1.rep <- sum(dev1.rep[] )
  chidev2.rep <- sum(dev2.rep[] )

  chidev1.pval<-step(chidev1.obs-chidev1.rep)
  chidev2.pval<-step(chidev2.obs-chidev2.rep)

  #   Deviance statistic
  dev<-   -2*sum(loglike[])
  dev.rep <-  -2*sum(loglike.rep[])
  dev.pval<-step(dev-dev.rep)

}", file="HarvestModQ22.txt")
  
# Setup Parameters
paramsMQ22 <- c("b", "tau",          # the rest are for the model checking
              "mu", "res", "stdres", "res.rep", "stdres.rep", "p.smaller",
              "p.inv", "chidev1.pval", "chidev2.pval", "chidev1.obs", "chidev2.obs",
              "chidev1.rep", "chidev2.rep", "dev", "dev.rep", "dev.pval")

bugMQ22.dat=list("x", "y", "N")  # what variable you need in the model

# Setup Initial Values
initMQ22.fun=function(){ 
  list(b=runif(3,-.8,-.2), tau=runif(1,.2,.8), y.rep=rnorm(N)) 
}
```


```{r, cache=TRUE}
#### Run Openbugs Simulation
set.seed(3508)
attach(HarvestingData)
HarvestingMQ22=bugs(bugMQ22.dat, initMQ22.fun, paramsMQ22, model.file="HarvestModQ22.txt",
    n.chains=NChain, n.iter=NSim, n.burnin=Burnin, n.thin=NThin , debug=FALSE)
detach(HarvestingData)

```

```{r}
# Get Simulation from OpenBugs
SArrayMQ22= HarvestingMQ22$sims.array   # Data Arrays
vname=attr(SArrayMQ22,"dimnames")[3][[1]]  # Variable Names
MQ22.coda <- as.mcmc.list(HarvestingMQ22)

```

```{r}
# Print Summary statistics of parameters oif Interest
RNames <- rownames(HarvestingMQ22[["summary"]][,c(1:3,5,7)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(HarvestingMQ22[["summary"]][,c(1:3,5,7)]))
df_Prt %>%
  filter(substr(Parameter,1,2)=="b[" |
           substr(Parameter,1,3)=="tau") %>% 
  kbl(booktabs = TRUE, digits = 4, 
      caption = "OpenBugs Summary - Harvesting Date vs. Yield (Model-2)") %>% 
  kable_styling(latex_options = "striped")
```

\medskip

\subsubsection{Checking Convergence and Auto-Correlation for Model-2}

```{r, fig.cap= "Trace-plots of $\\beta_1$, $\\beta_2$, $\\beta_3$ and $\\tau$ for Model-2", fig.height=3.5, fig.width=4.5}
# Plot TracePlots * b[1], b[2], b[3] and tau *

# Sampling 5000 points to generate "thinner" traceplots
set.seed(792)

L <- NSim-Burnin

S <- if (Sz < L) sort(sample(1:L, Sz, replace = FALSE)) else 1:Sz
 
# Build working dataframe
D_Workb1<- data.frame(ValCh1=SArrayMQ22[S,1,paste0("b[1]")],
                      ValCh2=SArrayMQ22[S,2,paste0("b[1]")],
                      ValCh3=SArrayMQ22[S,3,paste0("b[1]")])

D_Workb2 <- data.frame(ValCh1=SArrayMQ22[S,1,paste0("b[2]")],
                       ValCh2=SArrayMQ22[S,2,paste0("b[2]")],
                       ValCh3=SArrayMQ22[S,3,paste0("b[2]")])

D_Workb3 <- data.frame(ValCh1=SArrayMQ22[S,1,paste0("b[3]")],
                       ValCh2=SArrayMQ22[S,2,paste0("b[3]")],
                       ValCh3=SArrayMQ22[S,3,paste0("b[3]")])

D_Worktau <- data.frame(ValCh1=SArrayMQ22[S,1,paste0("tau")],
                        ValCh2=SArrayMQ22[S,2,paste0("tau")],
                        ValCh3=SArrayMQ22[S,3,paste0("tau")])

# Plot Traceplots for selected data-frames
P1 <- D_Workb1 %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta[1])) +
        theme_bw()
P2 <- D_Workb2 %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta[2])) +
        theme_bw()
P3 <- D_Workb3 %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta[3])) +
        theme_bw()
P4 <- D_Worktau %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(tau)) +
        theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)

# Remove Working Variable to free memory
remove(D_Workb1, D_Workb2, D_Workb3, D_Worktau )
```

```{r, fig.cap= "ACF-plots of $\\beta_1$, $\\beta_2$, $\\beta_3$ and $\\tau$ for Model-2 (max-Lag=50)"}
# Plot ACF Plots * b[1], b[2], b[3] and tau *

# Build working dataframe
D_Workb1 <- data.frame(ValCh1=SArrayMQ22[,1,paste0("b[1]")])
D_Workb2 <- data.frame(ValCh1=SArrayMQ22[,1,paste0("b[2]")])
D_Workb3 <- data.frame(ValCh1=SArrayMQ22[,1,paste0("b[3]")])
D_Worktau <- data.frame(ValCh1=SArrayMQ22[,1,paste0("tau")])

# Plot ACF Plots for selected data-frames
P1 <- ggAcf(D_Workb1$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(beta[1])) +
  ggtitle(NULL)+
  theme_bw()
P2 <- ggAcf(D_Workb2$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(beta[2])) +
  ggtitle(NULL)+
  theme_bw()
P3 <- ggAcf(D_Workb3$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(beta[3])) +
  ggtitle(NULL)+
  theme_bw()
P4 <- ggAcf(D_Worktau$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(tau)) +
  ggtitle(NULL)+
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)
# Remove Working Variable to free memory
remove(D_Workb1, D_Workb2, D_Workb3, D_Worktau )
```

\underline{Comment}:- We can see from trace and ACF plots that we have \underline{no evidence} of our estimates have not converged or are auto-correlated for \textbf{Model-2}.

In this sense, we can proceed with the comparative analysis between the two models.

\medskip

\subsubsection{Comparing Model-1 vs. Model-2}

In this subsection, we will compare \textit{DIC}\footnote{Instead of using the Deviance and DIC obtained from OpenBugs report, we calculated these statistics from our model. The complete model used as well as the detailed R-Code can be found at the Appendix of this document.} Statistics in order to identify the best between the two models.

```{r}
# Routines to Calculate DIC, Deviance of Model - Author: Michael Escobar (Thanks!)

# OBS>:- Flow remodeled to document each step

# Calculates the Deviance by hand
devNormFunc <- function(beta0, beta1, beta2, tau, x, y) {
  mu <- beta0 + beta1*x + beta2*x^2
  return(-2*sum(log(dnorm(y,mu,1/sqrt(tau)))))
}

CalcModelStats <- function (Model, TxtModel) {
  
  # STEP 1 - Calculate the Likelihood and respective Inverse
  M1.pinv <- Model$mean$p.inv       # Get 1/p(x)
  PLogLI <- -1*log(M1.pinv)                  # Get p(x)
  
  # Collects Inv.p(x) Likelihood, P[Log(Likelihood)]
  TbWork1 <- cbind(M1.pinv,1/M1.pinv,PLogLI)
  colnames(TbWork1) <- c("p.inv","p(x)","PLogLI");#TbWork1
  Pseudom2logL= -2*sum(PLogLI);#Pseudom2logL
  #cat("\n-------------------\n\n")
  
  # Collect Residuals (TbWork2)
  TbWork2<-cbind(Model$mean$res,
                 t(apply(Model$sims.list$res.rep,2,
                         function(x){c(quantile(x,probs=c(0.025,.975)),mean(x),sd(x))})))
  colnames(TbWork2)=c("res","2.5%","97.5%","mean","SD");#TbWork2
  #cat("\n-------------------\n\n")
  
  # Collect Std.Residuals (TbWork3)
  TbWork3<-cbind(Model$mean$stdres,
                 t(apply(Model$sims.list$stdres.rep,2,
                         function(x){c(quantile(x,probs=c(0.025,.975)),mean(x),sd(x))})))
  colnames(TbWork3)=c("stdres","2.5%","97.5%","mean","SD");#TbWork3
  #cat("\n-------------------\n\n")
  
  # Collect Deviance (TbWork4)
  M1.devrep<-Model$sims.list$dev.rep
  TbWork4<-c(Model$mean$dev,
             quantile(M1.devrep,probs=c(0.025,.975)),
             mean(M1.devrep),sd(M1.devrep))
  names(TbWork4)=c("Deviance","2.5%","97.5%","mean","SD");#TbWork4
  #cat("\n-------------------\n\n")
  
  # Collect Chi-Deviance (TbWork5)
  M1.chidev2rep<-Model$sims.list$chidev2.rep
  TbWork5<-c(Model$mean$chidev2.obs,
             quantile(M1.chidev2rep,probs=c(0.025,.975)),
             mean(M1.chidev2rep),sd(M1.chidev2rep))
  names(TbWork5)=c("Chi-Dev2","2.5%","97.5%","mean","SD");#TbWork5
  #cat("\n-------------------\n\n")
  
  # Calculates Non-Calibrated ("pval-stats") - REVIEW - 
  #apply(Model$sims.list$p.smaller,2,mean)
  #Model$mean$chidev2.pval
  #Model$mean$dev.pval
  #cat("\n-------------------\n\n")
  
  # Comparing intrinsic and self calculated value for Deviance:
  M1.dev <-Model$sims.list$dev
  M1.deviance <-Model$sims.list$deviance
  TbWork6 <-rbind(
    quantile(M1.dev,probs=c(0.025,.25,.5,.75,.975)),
    quantile(M1.deviance,probs=c(0.025,.25,.5,.75,.975)) )
  rownames(TbWork6)=c("SelfProgramed:","Openbugs Made:");# TbWork6    
  # cat("\n-------------------\n\n")
  
  # c(Model$mean$deviance,Model$mean$dev)    
  Dbar<-mean(M1.dev);#Dbar   # Calculated - Deviance 
  pd2<-0.5*var(M1.dev);#pd2
  
  
  # Setup Parameters for Model
  beta0Bar<- Model$mean$b[1]
  beta1Bar<- Model$mean$b[2]
  beta2Bar<- ifelse (dim(Model$sims.list$b)[2]==3,Model$mean$b[3],0)
  tauBar <- Model$mean$tau
  Dhat <- devNormFunc(beta0Bar, beta1Bar, beta2Bar, tauBar, 
                      HarvestingData$x,HarvestingData$y);#Dhat 
  pd1<-Dbar-Dhat;#pd1
  
  DIC1<-Dbar+pd1; #DIC1
  DIC2<-Dbar+pd2; #DIC2

  
  cat("\n------- Goodness of Fit Statistics for",TxtModel," --------")
  cat("\nDeviance: \n");
  print(TbWork6, dig=4)
  cat("\nDbar: ",format(Dbar, digits = 2, nsmall = 4))
  # cat("\nDhat: ",format(Dhat, digits = 2, nsmall = 4))
  cat("\npD:  ",format(pd2, digits = 2, nsmall = 4))
  cat("\nDIC: ",format(DIC2, digits = 2, nsmall = 4))
  cat("\n--------------------------------------------------------\n")
}

```

```{r}
CalcModelStats(HarvestingMQ21,"Model-1")
CalcModelStats(HarvestingMQ22,"Model-2")
```

\underline{Comment}:- After calculating the DIC and Deviance of both models, we obtained the smallest deviance and DIC for \textbf{Model-2} which would indicate in this case, it is the best model.

\medskip

\subsubsection{Bayes Factor by method Kuo-Mallick}

In order to calculate Bayes Factor by running the MCMC with the method Kuo-Mallick, we will use the following model:

\underline{Openbugs Model}

\begin{verbatim}
### Kuo-Mallick Model Selection
model{
  for (i in 1:N) {
    sy[i]~dnorm(mu[i],tau)
    mu[i]<- delta[1]*beta[1]*sx[i] + delta[2]*beta[2]*sx2[i]
  }
  
  for (ix in 1:2) {
    beta[ix]~dnorm(0,tau0)
  }
  
  tau~dgamma(.5,.01) 
  
  # Prior Distribution of delta[]
  for(k in 1:2){
    delta[k]~dbern(pp)
  }
  
  # Model Deltas
  for(i1 in 1:2){
    for(i2 in 1:2){
      mod[i1,i2]<-equals((2-i1),delta[1])*equals((2-i2),delta[2])
     }
  }

}
\end{verbatim}

```{r}
# Setup for Kuo-Mallick Model Variables - LAST VERSION

# Mean and Variance of Y
mu_y <- mean(HarvestingData$y)
sd_y <- sd(HarvestingData$y)

# Mean and Variance of X
mu_x <- mean(HarvestingData$x)
sd_x <- sd(HarvestingData$x)

# Mean and Variance of X^2
mu_x2 <- mean(HarvestingData$x^2)
sd_x2 <- sd(HarvestingData$x^2)

pp <- 0.5

# OBS:- I tested 'tau0' with several values and all decided in favor of M2 (which makes perfectly sense!) 
#       I ended up choosing a value inside the interval of 1/16<tau0<4
tau0 <- 0.3

# Standardizing Variables X and Y
sx <- (HarvestingData$x-mu_x)/sd_x          # Standardized X
sx2 <- (HarvestingData$x^2-mu_x2)/sd_x2     # Standardized X^2
sy <- (HarvestingData$y-mu_y)/sd_y          # Standardized y

cat("### Kuo-Mallick Model Selection
model{
  for (i in 1:N) {
    sy[i]~dnorm(mu[i],tau)
    mu[i]<- delta[1]*beta[1]*sx[i] + delta[2]*beta[2]*sx2[i]
  }
  
  for (ix in 1:2) {
    beta[ix]~dnorm(0,tau0)
  }
  
  tau~dgamma(.5,.01) 
  
  # Prior Distribution of delta[]
  for(k in 1:2){
    delta[k]~dbern(pp)
  }
  
  # Model Deltas
  for(i1 in 1:2){
    for(i2 in 1:2){
      mod[i1,i2]<-equals((2-i1),delta[1])*equals((2-i2),delta[2])
     }
  }

}", file="Harvest_KM.txt")


dataDiag_KM<-list("sx", "sx2", "sy", "N", "pp", "tau0")

initsDiag_KM<-function(){ list(beta=rnorm(2), tau=runif(1,.5,1))}

paramDiag_KM<-c("beta", "tau", "delta", "mod")

```

```{r, cache=TRUE}
set.seed(9212)
attach(HarvestingData)

HarvestDiag_KM<-bugs(dataDiag_KM,initsDiag_KM, paramDiag_KM, model.file="Harvest_KM.txt",
                        n.chains=1, n.iter=20000, n.burnin=5000,
                        n.thin=10)
detach(HarvestingData)

```


```{r}
# Calculus of abeta[]'s
abeta1 <- HarvestDiag_KM$sims.array[,,paste0("beta[1]")]*sd_x/sd_y
abeta2 <- HarvestDiag_KM$sims.array[,,paste0("beta[2]")]*sd_x/sd_y

t_abeta1 <- c(mean(abeta1),sd(abeta1),quantile(abeta1,c(.025,.5,.975)))
t_abeta2 <- c(mean(abeta2),sd(abeta2),quantile(abeta2,c(.025,.5,.975)))

abeta <- rbind(t_abeta1,t_abeta2)
colnames(abeta) <- c("mean","sd","2.5%","50%","97.5%")
rownames(abeta) <- c("abeta[1]","abeta[2]")
```


```{r}
# Print Summary statistics of parameters oif Interest
RNames <- rownames(HarvestDiag_KM[["summary"]][,c(1:3,5,7)]) # List of parameters
df_KM <- data.frame(Parameter = RNames)
df_KM <- cbind(df_KM, as_tibble(HarvestDiag_KM[["summary"]][,c(1:3,5,7)]))
df_KM %>%
  kbl(booktabs = TRUE, digits = 4,
      caption = "OpenBugs Summary - Kuo-Mallik Model Selection Statistics") %>% 
  kable_styling(latex_options = "striped")
```

```{r}
# Jeffrey's Criteria for Bayes Factor
JeffCrit <- function(BF) {
  if (BF>=0.0 && BF<=.5) return("Not worth more than a bare mention")
  else{
    if (BF>.5 && BF<=1.0) return("Substantial")
    else {
      if (BF>1.0 && BF<=2.0) return("Strong")
      else return("Decisive")
    }
  }
}

# Kass, Raftery's Criteria for Bayes Factor
KassRafteryCrit <- function(BF) {
  if (BF>=0.0 && BF<=2.0) return("Not worth more than a bare mention")
  else{
    if (BF>2.0 && BF<=6.0) return("Positive")
    else {
      if (BF>6.0 && BF<=10.0) return("Strong")
      else return("Decisive")
    }
  }
}

Kuo_MallickCrit <- function(PModA, PModB, TxtModA, TxtModB) {
  BF_KM <- PModA/PModB
  # Print Kuo-Mallik Bayes Factor Analysis for Model-A over Model-B
  cat("\n-------- Kuo-Mallik Bayes Factor Analysis (",TxtModA,"/",TxtModB,") ---------")
  cat("\n\nPosterior Probability",TxtModA,"| Data: ",format(PModA, digits = 2, nsmall = 4))
  cat("\n\nPosterior Probability",TxtModB,"| Data: ",format(PModB, digits = 2, nsmall = 4))
  cat("\n\n>>> Bayes Factor : ",format(BF_KM, digits = 2, nsmall = 4))
  cat("\n\n>>> Jeffrey's Evidence of",TxtModA,"over",TxtModB,": ",JeffCrit(log10(BF_KM)))
  cat("\n\n>>> Kass/Raftery's Evidence of",TxtModA,"over",TxtModB,": ",KassRafteryCrit(2*log(BF_KM)))
  cat("\n---------------------------------------------------------------\n")
}

```

IN the present analysis, Model-1 is represented by parameter \textit{mod[1,2]} and Model-2 by the parameter \textit{mod[1,1]}.

```{r}
# Calculation of BF - It is equivalent to compare
#    mod[1,1] (Model-2) agains mod[1,2] (Model-1)
PM1 <- df_KM[which(df_KM$Parameter=="mod[1,2]"),"mean"]#;PM1  # This is Probability of Model-1
PM2 <- df_KM[which(df_KM$Parameter=="mod[1,1]"),"mean"]#;PM2  # This is Probability of Model-2

Kuo_MallickCrit (PM2, PM1, "M2", "M1")
```

\underline{Comment}:- From \textit{Kuo-Mallik} Method we obtained a Bayes Factor(BF) of M2 over M1 equals to $23.9270$. Using Jeffrey's and Kass/Raftery's Criteria to compare the models, both provided the similar results, i.e., \textit{there is \textbf{STRONG} evidence that Model-2 is better than Model-1}.

Considering this, besides the \textit{highest posterior probability model}, our decision is in favor of \textbf{Model-2}.

\subsection{item (b)}

For model 1, look at the residuals for the model using functions 1, 2, and 3. That is, calculate 1) the residuals, 2) the standardized residuals, and 3) the chance of getting a more extreme observation. For the residual and the standardize residual, please calculate the distribution of these statistics under the predictive distribution. Comment on the results of these statistics for the observation. Also, comment on how well you think the model fits the data.

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

The OpenBugs simulation of \textit{Model-1} generated the following results:

\medskip

\subsubsection{Residuals}

The Residuals for \textbf{Model-1} is as follows:

```{r}
# Item (1) - Print Residuals
RNames <- rownames(HarvestingMQ21[["summary"]][,c(1:3,5,7)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(HarvestingMQ21[["summary"]][,c(1:3,5,7)]))
df_Prt %>%
  filter(substr(Parameter,1,4)=="res[") %>% 
  kbl(booktabs = TRUE, digits = 4,
      caption = "OpenBugs Summary - Residuals for Model-1") %>% 
  kable_styling(latex_options = "striped")
```

\medskip

\subsubsection{Standardized Residuals}

The Standardized Residuals for \textbf{Model-1} is as follows:


```{r}
# Item (2) - Print Standardized Residuals
RNames <- rownames(HarvestingMQ21[["summary"]][,c(1:3,5,7)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(HarvestingMQ21[["summary"]][,c(1:3,5,7)]))
df_Prt %>%
  filter(substr(Parameter,1,7)=="stdres[") %>% 
  kbl(booktabs = TRUE, digits = 4,
      caption = "OpenBugs Summary - Standardized Residuals for Model-1") %>% 
  kable_styling(latex_options = "striped")
```

\medskip

\subsubsection{Chance of Getting Extreme Observations}

The Chance of Getting Extreme Observations for \textbf{Model-1} is as follows:

```{r}
# Item (3) - Print Chance of Getting Extreme Observations
RNames <- rownames(HarvestingMQ21[["summary"]][,c(1:2)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(HarvestingMQ21[["summary"]][,c(1:2)]))
df_Prt %>%
  filter(substr(Parameter,1,10)=="p.smaller[") %>% 
  kbl(booktabs = TRUE, digits = 4,
      caption = "OpenBugs Summary - Chance of Extreme Observations for Model-1") %>% 
  kable_styling(latex_options = "striped")
```

\medskip

\subsubsection{Distribution of Residuals and Standardized Residuals under the Predictive Distribution}

The Distribution of Residuals and Standardized Residuals under the Predictive Distribution can be represented by the following posterior distributions:

```{r}
# Get Distribution of Residuals/Std Residuals under Predictive Distribution
SArrayDiagM1= HarvestingMQ21$sims.array      # Data Arrays
vname=attr(SArrayDiagM1,"dimnames")[3][[1]]  # Variable Names

SArrayDiagM2= HarvestingMQ22$sims.array      # Data Arrays
vname=attr(SArrayDiagM2,"dimnames")[3][[1]]  # Variable Names

```

```{r, fig.cap= "Model-1 - Residuals under Predictive Distribution"}
# Plot Sample densities to Compare Distributions of Residuals

# Build working dataframe
D_WorkRes <- as_tibble(data.frame(LvlStd=as.vector(
  SArrayDiagM1[,1,c(paste0("res.rep[", 1:16, "]"))]), Chain = "C1"))
D_WorkstdRes <- as_tibble(data.frame(LvlStd=as.vector(
  SArrayDiagM1[,1,c(paste0("stdres.rep[", 1:16, "]"))]), Chain = "C1"))

# Ploting the Sensities
P1 <- D_WorkRes %>%
  ggplot(aes(x = LvlStd))+
  geom_density(aes(x=LvlStd, group=Chain, colour=Chain), size=0.8)+ 
  labs(x = "Residuals", y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()
P2 <- D_WorkstdRes %>%
  ggplot(aes(x = LvlStd))+
  geom_density(aes(x=LvlStd, group=Chain, colour=Chain), size=0.8)+ 
  labs(x = "Std.Residuals", y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

ggpubr::ggarrange(P1+theme(legend.position="none"), 
                  P2+theme(legend.position="none"), ncol = 1, nrow = 2)
remove(D_WorkRes,D_WorkstdRes)

```

\subsubsection{Overview of Model-1}

Overall, the goodness of fit of \textbf{Model-1} to our data is not good.

There are a few reasons for it:

\begin{itemize}
    \item The probability of Model-1, given the data, is around $2.1\%$, which is very low if we compare it among the remaining alternative models;
    \item The DIC and Deviance of this model are both higher when compared, for instance, with alternative Model-2;
    \item The shape of scatter-plot of the source data suggests a quadratic relation between $X$ and $Y$ and this may impose limitations when we try to fit a purely linear model to the data.
\end{itemize}

\subsubsection{Comparison between Residuals for Models 1 and 2}

Comparing a sample of $30,000$ residuals from both models, it becomes clear that Model-1 has poor adjustment when compared with Model-2. The distribution of the Residuals, Absolute and Relative Errors from Model-1 (M1) are visually more sparse than in Model-2 (M2). 

```{r}
# Sample points for Residuals
set.seed(792)
LR <-  length(SArrayDiagM1[,1,c(paste0("res.rep[", 1:16, "]"))])
S <- sort(sample(1:LR, 30000, replace = FALSE))

# Build working dataframe
D_WorkRes <- rbind(
  data.frame(
    Iter = c(1:length(S)),
    Res=as.vector(
      SArrayDiagM1[,1,c(paste0("res.rep[", 1:16, "]"))][S]), Model = "M1"),
  data.frame(
    Iter = c(1:length(S)),
    Res=as.vector(
      SArrayDiagM2[,1,c(paste0("res.rep[", 1:16, "]"))][S]), Model = "M2"))

# Calculate Absolute Error for each model
D_WorkAbsErr <- rbind(
  data.frame(
    Iter = c(1:length(S)),
    AbsErr=as.vector(SArrayDiagM1[,1,c(paste0("res.rep[", 1:16, "]"))][S])/LR, Model = "M1"),
  data.frame(
    Iter = c(1:length(S)),
    AbsErr=as.vector(SArrayDiagM2[,1,c(paste0("res.rep[", 1:16, "]"))][S])/LR, Model = "M2"))

# Calculate Relative Error for each model
D_WorkRelErr <- rbind(
  data.frame(
    Iter = c(1:length(S)),
    RelErr=as.vector(SArrayDiagM1[,1,c(paste0("res.rep[", 1:16, "]"))][S]/
                    SArrayDiagM1[,1,c(paste0("mu[", 1:16, "]"))][S]), Model = "M1"),
  data.frame(
    Iter = c(1:length(S)),
    RelErr=as.vector(SArrayDiagM2[,1,c(paste0("res.rep[", 1:16, "]"))][S]/
                    SArrayDiagM2[,1,c(paste0("mu[", 1:16, "]"))][S]), Model = "M2"))

```


```{r, fig.cap= "Model-2 vs. Model 1 - Residuals Compared (sample 30,000)"}
# Ploting Residuals
D_WorkRes %>%
  ggplot(aes(x=Iter))+
  geom_point(aes(y=Res, colour=Model), size=0.6)+ 
  labs(x = "Iteration", y = "Residual") +
  scale_color_manual(values = cbp2)+
  theme_bw()
```

```{r, fig.cap= "Model-2 vs. Model 1 - Absolute and Relative Error Compared"}
# Ploting Absolute error
P2 <- D_WorkAbsErr %>%
  ggplot(aes(x=Iter))+
  geom_point(aes(y=AbsErr, colour=Model), size=0.6)+ 
  labs(x = "Iteration", y = "Absolute Error") +
  scale_color_manual(values = cbp2)+
  theme_bw()

# Ploting Relative error
P3 <- D_WorkRelErr %>%
  ggplot(aes(x=Iter))+
  geom_point(aes(y=RelErr, colour=Model), size=0.6)+ 
  labs(x = "Iteration", y = "Relative Error") +
  scale_color_manual(values = cbp2)+
  theme_bw()

ggpubr::ggarrange(P2+theme(axis.title.x=element_blank()), 
                  P3+theme(axis.title.x=element_blank()), ncol = 1, nrow = 2)


remove(D_WorkAbsErr, D_WorkRelErr, D_WorkRes)
```

In this case, there are evidences that \textbf{Model-2} outperforms \textit{Model-1}. We could explore further other alternative models but this is out of the scope of the current question.

\underline{Final Remark}:- This question was very useful to understand the Bayesian Process of Model Analysis and Diagnostics. 


\pagebreak

\begin{thebibliography}{6}

\bibitem{GelmanEtAll} 
Gelman, A., Carlin, J.B., Stern, H.S., Dunson, D.B., Vehtari, A., Rubin, D.B.
\textit{Bayesian Data Analysis}. pp.34 - CRC Press, 2014.

\bibitem{GelmanHill} 
Gelman, A., Hill, J.
\textit{Data Analysis using Regression and Multilevel/Hierarchical Models}, Cambridge Press, 2007.

\bibitem{MarinRobert} 
Marin, J. M., Robert, C.
\textit{Bayesian Essentials with R}, 2nd. Ed. pp.49 - Springer, 2014.

\bibitem{Geweke1}
Geweke J.
\textit{Bayesian Contemporary Econometrics and Statistics}. London: Wiley, 2005.


\bibitem{Geweke2}
Geweke J.
\textit{Evaluating the accuracy of sampling-based approaches to calculating posterior moments}, Bayesian Statistics 4, Clarendon Press, Oxford, UK, (1992)


\bibitem{Ntzoufras}
Ntzoufras I.
\textit{Bayesian Modeling Using WinBUGS}, Wiley, 2009

\end{thebibliography}

\pagebreak

\section{Appendix - R-Code}

```{r, echo=TRUE, eval=FALSE}
library(tidyverse)
library(R2OpenBUGS)
library(kableExtra)
library(ggplot2)
library(forecast)
library(coda)
# library(boa)

# The palette with black - Used in Graphs with :
cbp1 <- c("#999999", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbp2 <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbp3 <- c("#FFDB6D", "#C4961A", "#F4EDCA", "#D16103", 
          "#C3D7A4", "#52854C", "#4E84C4", "#293352")

#
#data from Healy, page 90.
#  (MJR Healy, 1988, Glim: An Introduction, Clarendon Press: Oxford.)
#  Looking to see if Smoking is a risk factor for hypertension, controlling for obesity, snoring, and gender
#  Note 1: there was no males or females who were smokers and obese and who did not snore (so 1 1 0 had no exposures)
#  Note 2: here we are simply looking at the effect of smoking given the other factors.  We are ignoring the possibility that 
#  obesity might be related to smoking or that snoring might be strongly effected by smoking and obesity.  
#  In modern epi, these factors might be consider to be in the <<causal path>> and perhaps you might not control for them in this way.
cat(
  "smoke  obese  snore male hypoten n
0 0 0 1 5 60
0 0 0 0 10 149
1 0 0 1 2 17
1 0 0 0 6 16
0 1 0 1 1 12
0 1 0 0 2 9
0 0 1 1 36 187
0 0 1 0 28 138
1 0 1 1 13 85
1 0 1 0 4 39
0 1 1 1 15 51
0 1 1 0 11 28
1 1 1 1 8 23
1 1 1 0 4 12
", file= "Data/SmokeHyperData.txt")

# Setup Data-set - Read Data
SmokeHyper=read.table("Data/SmokeHyperData.txt",header=TRUE,sep = "")

# Setup Variables
N=nrow(SmokeHyper)  # Number of Items in data-set

# Setup OpenBugs running parameters
NSim <- 30000    # No. of simulations for productio
NChain <- 3      # No. of chains for production
NThin <- 50      # n.thin parameter for production
Burnin <- 10000  # Burn-In parameter for production
Sz <- 5000       # Size of samples for trace/acf plots


# Printing the Data-Frame
SmokeHyper %>%
  kbl(booktabs = TRUE, digits = 4,
      caption = "Data - Relationship between Hypertension and Smoking") %>% 
  kable_styling(latex_options = "striped")


cat("
model{
  for(i in 1:N){
   hypoten[i] ~ dbin(mu[i], n[i])
   logit(mu[i]) <- b0 + b.smok*smoke[i]+ b.ob*obese[i]+ b.sn*snore[i] + 
     b.male*male[i] + b.smsn*smoke[i]*snore[i] + b[i]
    b[i] ~dnorm(0, tau.b)
   }
  b.smok ~ dnorm(0, .04) # so, sd =5.  exp(5) ~ 148 which is huge
  b.ob ~ dnorm(0, .04) 
  b.sn ~ dnorm(0, .04) 
  b.male ~ dnorm(0, .04) 
  b0 ~ dnorm(0, .04) 
  b.smsn ~dnorm(0, .04)
  sd.b ~ dunif(0, 5)
  tau.b <- 1/pow(sd.b,2)
  }
  ", file="SmokeHyperMod3.txt")

# Setup Parameters
paramsM0=c("b0", "b.smok", "b.ob", "b.sn", "b.male", "b.smsn" , "sd.b")

bugM0.dat=list("hypoten", "n", "smoke", "obese", "snore", "male", "N")  # what variable you need in the model


# Setup Initial Values
initM0.fun=function(){ list(  b=runif(N,-.8,-.2), 
                              b0=runif(1,-.8,-.2),
                              b.smok=runif(1,-.8,-.2),b.ob=runif(1,-.8,-.2), b.sn=runif(1,-.8,-.2),
                              b.male=runif(1,-.8,-.2), b.smsn=runif(1, -8,-.2), sd.b=runif(1,.2,.8)	
) }

#### Could change the code below...
# Run Open Bugs - NO BURNIN / NO THINN
set.seed(2602)
attach(SmokeHyper)
SmokeHypeBaseM0=bugs(bugM0.dat, initM0.fun, paramsM0, model.file="SmokeHyperMod3.txt",
                     n.chains=NChain, n.iter=NSim, n.burnin=0, n.thin=1, debug=FALSE)
detach(SmokeHyper)


# Get Simulation from OpenBugs
SArrayM0= SmokeHypeBaseM0$sims.array   # Data Arrays
vname=attr(SArrayM0,"dimnames")[3][[1]]  # Variable Names


# Print Summary statistics of parameters oif Interest
RNames <- rownames(SmokeHypeBaseM0[["summary"]][,c(1:3,5,7)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(SmokeHypeBaseM0[["summary"]][,c(1:3,5,7)]))
df_Prt %>%
  kbl(booktabs = TRUE, digits = 4, 
      caption = "OpenBugs Summary - Hypertension and Smoke Study (Run-0)") %>% 
  kable_styling(latex_options = "striped")

# Plot TracePlots * SIGMA, BETA0, BETA.SMOKE and BETA.OBESITY *

# Sampling 5000 points to generate "thinner" traceplots
set.seed(312)

L <- NSim-Burnin

OldSz <- Sz  
Sz <- L       # Override Original value

S <- if (Sz < L) sort(sample(1:L, Sz, replace = FALSE)) else 1:Sz

# Build working dataframe
D_WorkSigma <- data.frame(ValCh1=SArrayM0[S,1,paste0("sd.b")],
                          ValCh2=SArrayM0[S,2,paste0("sd.b")],
                          ValCh3=SArrayM0[S,3,paste0("sd.b")])

D_WorkBeta0 <- data.frame(ValCh1=SArrayM0[S,1,paste0("b0")],
                          ValCh2=SArrayM0[S,2,paste0("b0")],
                          ValCh3=SArrayM0[S,3,paste0("b0")])

D_WorkBetaSmok <- data.frame(ValCh1=SArrayM0[S,1,paste0("b.smok")],
                             ValCh2=SArrayM0[S,2,paste0("b.smok")],
                             ValCh3=SArrayM0[S,3,paste0("b.smok")])

D_WorkBetaObes <- data.frame(ValCh1=SArrayM0[S,1,paste0("b.ob")],
                             ValCh2=SArrayM0[S,2,paste0("b.ob")],
                             ValCh3=SArrayM0[S,3,paste0("b.ob")])

# Plot Traceplots for selected data-frames
P1 <- D_WorkSigma %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(sigma)) +
  theme_bw()
P2 <- D_WorkBeta0 %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta[0])) +
  theme_bw()
P3 <- D_WorkBetaSmok %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta[Smoke])) +
  theme_bw()
P4 <- D_WorkBetaObes %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta[Obesity])) +
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)

# Remove Working Variable to free memory
Sz <- OldSz # Restore original value
remove(OldSz, D_WorkSigma, D_WorkBeta0, D_WorkBetaSmok, D_WorkBetaObes )

# Plot ACF Plots * SIGMA, BETA0, BETA.SMOKE and BETA.OBESITY *

# Build working dataframe
D_WorkSigma <- data.frame(ValCh1=SArrayM0[,1,paste0("sd.b")])
D_WorkBeta0 <- data.frame(ValCh1=SArrayM0[,1,paste0("b0")])
D_WorkBetaSmok <- data.frame(ValCh1=SArrayM0[,1,paste0("b.smok")])
D_WorkBetaObes <- data.frame(ValCh1=SArrayM0[,1,paste0("b.ob")])

# Plot ACF Plots for selected data-frames
P1 <- ggAcf(D_WorkSigma$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(sigma)) +
  ggtitle(NULL)+
  theme_bw()
P2 <- ggAcf(D_WorkBeta0$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta[0])) +
  ggtitle(NULL)+
  theme_bw()
P3 <- ggAcf(D_WorkBetaSmok$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta[Smoke])) +
  ggtitle(NULL)+
  theme_bw()
P4 <- ggAcf(D_WorkBetaObes$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta[Obesity])) +
  ggtitle(NULL)+
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)
# Remove Working Variable to free memory
remove(D_WorkSigma, D_WorkBeta0, D_WorkBetaSmok, D_WorkBetaObes )

# Setup Parameters for Run-01

paramsM1 <- paramsM0

bugM1.dat <- bugM0.dat

initM1.fun <- initM0.fun

# Run Open Bugs - BURNIN=10,000 / THINN=50
set.seed(2212)
attach(SmokeHyper)
SmokeHypeBaseM1=bugs(bugM1.dat, initM1.fun, paramsM1, model.file="SmokeHyperMod3.txt",
                     n.chains=NChain, n.iter=NSim, n.burnin=Burnin, n.thin=NThin , debug=FALSE)
detach(SmokeHyper)


# Get Simulation from OpenBugs
SArrayM1= SmokeHypeBaseM1$sims.array   # Data Arrays
vname=attr(SArrayM1,"dimnames")[3][[1]]  # Variable Names


# Print Summary statistics of parameters oif Interest
RNames <- rownames(SmokeHypeBaseM1[["summary"]][,c(1:3,5,7)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(SmokeHypeBaseM1[["summary"]][,c(1:3,5,7)]))
df_Prt %>%
  kbl(booktabs = TRUE, digits = 4, 
      caption = "OpenBugs Summary - Hypertension and Smoke Study (Run-1)") %>% 
  kable_styling(latex_options = "striped")

# Plot TracePlots * SIGMA, BETA0, BETA.SMOKE and BETA.OBESITY *

# Sampling 5000 points to generate "thinner" traceplots
set.seed(312)

L <- NSim-Burnin

OldSz <- Sz  
Sz <- L       # Override Original value

S <- if (Sz < L) sort(sample(1:L, Sz, replace = FALSE)) else 1:Sz

# Build working dataframe
D_WorkSigma <- data.frame(ValCh1=SArrayM1[S,1,paste0("sd.b")],
                          ValCh2=SArrayM1[S,2,paste0("sd.b")],
                          ValCh3=SArrayM1[S,3,paste0("sd.b")])

D_WorkBeta0 <- data.frame(ValCh1=SArrayM1[S,1,paste0("b0")],
                          ValCh2=SArrayM1[S,2,paste0("b0")],
                          ValCh3=SArrayM1[S,3,paste0("b0")])

D_WorkBetaSmok <- data.frame(ValCh1=SArrayM1[S,1,paste0("b.smok")],
                             ValCh2=SArrayM1[S,2,paste0("b.smok")],
                             ValCh3=SArrayM1[S,3,paste0("b.smok")])

D_WorkBetaObes <- data.frame(ValCh1=SArrayM1[S,1,paste0("b.ob")],
                             ValCh2=SArrayM1[S,2,paste0("b.ob")],
                             ValCh3=SArrayM1[S,3,paste0("b.ob")])

# Plot Traceplots for selected data-frames
P1 <- D_WorkSigma %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(sigma)) +
  theme_bw()
P2 <- D_WorkBeta0 %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta[0])) +
  theme_bw()
P3 <- D_WorkBetaSmok %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta[Smoke])) +
  theme_bw()
P4 <- D_WorkBetaObes %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta[Obesity])) +
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)

# Remove Working Variable to free memory
Sz <- OldSz # Restore original value
remove(OldSz, D_WorkSigma, D_WorkBeta0, D_WorkBetaSmok, D_WorkBetaObes )

# Plot ACF Plots * SIGMA, BETA0, BETA.SMOKE and BETA.OBESITY *

# Build working dataframe
D_WorkSigma <- data.frame(ValCh1=SArrayM1[,1,paste0("sd.b")])
D_WorkBeta0 <- data.frame(ValCh1=SArrayM1[,1,paste0("b0")])
D_WorkBetaSmok <- data.frame(ValCh1=SArrayM1[,1,paste0("b.smok")])
D_WorkBetaObes <- data.frame(ValCh1=SArrayM1[,1,paste0("b.ob")])

# Plot ACF Plots for selected data-frames
P1 <- ggAcf(D_WorkSigma$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(sigma)) +
  ggtitle(NULL)+
  theme_bw()
P2 <- ggAcf(D_WorkBeta0$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta[0])) +
  ggtitle(NULL)+
  theme_bw()
P3 <- ggAcf(D_WorkBetaSmok$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta[Smoke])) +
  ggtitle(NULL)+
  theme_bw()
P4 <- ggAcf(D_WorkBetaObes$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta[Obesity])) +
  ggtitle(NULL)+
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)
# Remove Working Variable to free memory
remove(D_WorkSigma, D_WorkBeta0, D_WorkBetaSmok, D_WorkBetaObes )

# Prepare data to plot densities to Compare Distributions of 
# * SIGMA, BETA0, BETA.SMOKE and BETA.OBESITY *

set.seed(9023)

L <- NSim-Burnin

S <- if (Sz < L) sort(sample(1:L, Sz, replace = FALSE)) else 1:Sz

# Build working dataframe
D_WorkSigma <- as_tibble(rbind(data.frame(LvlStd=as.vector(SArrayM1[S,1,paste0("sd.b")]), Chain = "C1"),
                               data.frame(LvlStd=as.vector(SArrayM1[S,2,paste0("sd.b")]), Chain = "C2"),
                               data.frame(LvlStd=as.vector(SArrayM1[S,3,paste0("sd.b")]), Chain = "C3")))
D_WorkBeta0 <- as_tibble(rbind(data.frame(LvlStd=as.vector(SArrayM1[S,1,paste0("b0")]), Chain = "C1"),
                               data.frame(LvlStd=as.vector(SArrayM1[S,2,paste0("b0")]), Chain = "C2"),
                               data.frame(LvlStd=as.vector(SArrayM1[S,3,paste0("b0")]), Chain = "C3")))
D_WorkBetaSmok <- as_tibble(rbind(data.frame(LvlStd=as.vector(SArrayM1[S,1,paste0("b.smok")]), Chain = "C1"),
                                  data.frame(LvlStd=as.vector(SArrayM1[S,2,paste0("b.smok")]), Chain = "C2"),
                                  data.frame(LvlStd=as.vector(SArrayM1[S,3,paste0("b.smok")]), Chain = "C3")))
D_WorkBetaObes <- as_tibble(rbind(data.frame(LvlStd=as.vector(SArrayM1[S,1,paste0("b.ob")]), Chain = "C1"),
                                  data.frame(LvlStd=as.vector(SArrayM1[S,2,paste0("b.ob")]), Chain = "C2"),
                                  data.frame(LvlStd=as.vector(SArrayM1[S,3,paste0("b.ob")]), Chain = "C3")))

# Calculates Batch Means and respective SE - Author: Michael Escobar (thank you!)
CalcBatchMeans <- function (x, Batn = 50) {
  BigN=length(x)
  BatInc=ceiling((1:BigN)/(BigN/Batn) )
  BM=tapply(x,BatInc,mean)
  return(list(MCE=(sd(BM)/sqrt(length(BM))), BM=BM))
}

# Calculates the Standard Error via Auto-Correlation Function - Author: Michael Escobar (thank you!)
CalcAcSe=function(x,lag.max=50){
  autoc=(acf(x,lag.max=lag.max,plot=FALSE))$acf
  sd(x)/sqrt(length(x))*sqrt(-1+2*sum(autoc))
}

CalcChainStats <- function (parm, chain, TxtParm) {
  L <- CalcBatchMeans(SArrayM1[,chain,paste0(parm)])
  S <- CalcAcSe(SArrayM1[,chain,paste0(parm)],120)
  cat("\n---- Summary Statistics for",TxtParm,"(Chain ",chain,") -----")
  cat("\nB-Mean : ",format(mean(L$BM), digits = 2, nsmall = 4)) 
  cat("\nB-S.E.: ",format(L$MCE, digits = 2, nsmall = 6))
  CI_up <- mean(L$BM)+2*L$MCE; CI_lo <- mean(L$BM)-2*L$MCE; 
  cat("\n95% Credible Region (", 
      format(CI_lo, digits = 2, nsmall = 4), ",",
      format(CI_up, digits = 2, nsmall = 4),")\n")
  cat("\n(ACF) S.E.: ",format(S, digits = 2, nsmall = 6))
  CI_up <- mean(L$BM)+2*S; CI_lo <- mean(L$BM)-2*S; 
  cat("\n(ACF) 95% Credible Region (", 
      format(CI_lo, digits = 2, nsmall = 4), ",",
      format(CI_up, digits = 2, nsmall = 4),")\n")
  cat("---------------------------------------------------\n")
}

# Calculates Posterior Means using Batch-Means and ACF - SIGMA
CalcChainStats("sd.b",1,"SIGMA")
CalcChainStats("sd.b",2,"SIGMA")
CalcChainStats("sd.b",3,"SIGMA")

D_WorkSigma %>%
  ggplot(aes(x = LvlStd))+
  geom_density(aes(x=LvlStd, group=Chain, colour=Chain), size=0.8)+ 
  labs(x = expression(sigma), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

# Calculates Posterior Means using Batch-Means and ACF - BETA0
CalcChainStats("b0",1,"BETA0")
CalcChainStats("b0",2,"BETA0")
CalcChainStats("b0",3,"BETA0")


D_WorkBeta0 %>%
  ggplot(aes(x = LvlStd))+
  geom_density(aes(x=LvlStd, group=Chain, colour=Chain), size=0.8)+ 
  labs(x = expression(beta[0]), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

# Calculates Posterior Means using Batch-Means and ACF - BETA-SMOKE
CalcChainStats("b.smok",1,"BETA-SMOKE")
CalcChainStats("b.smok",2,"BETA-SMOKE")
CalcChainStats("b.smok",3,"BETA-SMOKE")



D_WorkBetaSmok %>%
  ggplot(aes(x = LvlStd))+
  geom_density(aes(x=LvlStd, group=Chain, colour=Chain), size=0.8)+ 
  labs(x = expression(beta[Smoke]), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

# Calculates Posterior Means using Batch-Means and ACF - BETA-OBESITY
CalcChainStats("b.ob",1,"BETA-OBESITY")
CalcChainStats("b.ob",2,"BETA-OBESITY")
CalcChainStats("b.ob",3,"BETA-OBESITY")


D_WorkBetaObes %>%
  ggplot(aes(x = LvlStd))+
  geom_density(aes(x=LvlStd, group=Chain, colour=Chain), size=0.8)+ 
  labs(x = expression(beta[Obesity]), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

# Remove Working Variables and workdataframes used in this question to free memory
remove(D_WorkSigma, D_WorkBeta0, D_WorkBetaSmok, D_WorkBetaObes )

# Prepare Structures for CODA
Chn.sigma <- list( C1=mcmc(SArrayM1[,1,paste0("sd.b")]),
                   C2=mcmc(SArrayM1[,2,paste0("sd.b")]),
                   C3=mcmc(SArrayM1[,3,paste0("sd.b")]))
Chn.b0 <- list( C1=mcmc(SArrayM1[,1,paste0("b0")]),
                C2=mcmc(SArrayM1[,2,paste0("b0")]),
                C3=mcmc(SArrayM1[,3,paste0("b0")]))
Chn.bsmok <- list( C1=mcmc(SArrayM1[,1,paste0("b.smok")]),
                   C2=mcmc(SArrayM1[,2,paste0("b.smok")]),
                   C3=mcmc(SArrayM1[,3,paste0("b.smok")]))
Chn.bob <- list( C1=mcmc(SArrayM1[,1,paste0("b.ob")]),
                 C2=mcmc(SArrayM1[,2,paste0("b.ob")]),
                 C3=mcmc(SArrayM1[,3,paste0("b.ob")]))

# Calculate Summary MCMC of estimates
CalcDiags <- function (MC, TxtParm) {
  MMC <- cbind(MC$C1,MC$C2,MC$C3)
  colnames(MMC) <- c("Chain1","Chain2","Chain3")
  cat("\n--------- CODA Summary Statistics for",TxtParm,"---------\n")
  print(summary(mcmc(MMC)))
  cat(">>> Effective Size:\n")
  print(effectiveSize(MMC))
  cat("\n>>> GEWEKE Diagnostics:")
  print(geweke.diag(MMC))
  geweke.plot(mcmc(MMC))
  cat(">>> GELMAN Diagnostics:\n")
  print(gelman.diag(MC))
  gelman.plot(MC)
}


CalcDiags(Chn.sigma, "SIGMA")

CalcDiags(Chn.b0, "BETA-0")

CalcDiags(Chn.bsmok, "BETA-SMOKE")

CalcDiags(Chn.bob, "BETA-OBESITY")

# Setup Data-set - Read Data
HarvestingData <- data.frame( x=c(16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46),
                              y=c(2508,2518,3304,3423,3057,3190,3500,3883,3823,3646,3708,
                                  3333,3517,3241,3103,2776))

# Setup Variables
N=nrow(HarvestingData)  # Number of Items in data-set

# Setup OpenBugs running parameters
NSim <- 30000    # No. of simulations for productio
NChain <- 3      # No. of chains for production
NThin <- 10      # n.thin parameter for production
Burnin <- 10000  # Burn-In parameter for production
Sz <- 5000       # Size of samples for trace/acf plots


# Printing the Data-Frame
HarvestingData %>%
  kbl(booktabs = TRUE, digits = 1,
      caption = "(x):Harvesting Date (in days) vs. (y):Yield (in Kg/Ha)") %>% 
  kable_styling(latex_options = "striped")


HarvestingData %>%
  ggplot(aes(x=x, y=y))+
  geom_point(size=2.5)+ 
  labs(x = "X (# of days after flowering)", y = "Y (Yield in Kg/ha)") +
  theme_bw()

# MODEL Q2_1
cat("### Model 1 -
model{
  for (i in 1:N) {
    y[i]~dnorm(mu[i],tau)
    mu[i]<- b[1] + b[2]*(x[i]-31)
 
    # Get the residuals for the observed value
    res[i] <- (y[i]-mu[i])           # Estimate the residual for this model  - Item (1)
    stdres[i] <- res[i]*sqrt(tau)    # Calculate the standard residuals - Item (2)
    
    dev1.obs[i] <- pow(res[i],2)
    dev2.obs[i] <- pow(stdres[i],2)
    
    # Get a replicated Sample - sample of the predictive distribution
    y.rep[i]~dnorm(mu[i],tau)
    p.smaller[i] <- step(y[i]-y.rep[i])  # Check to see the probability of getting extreme value - Item (3)
    
    # Residual and Moments replicated - this gives the predicted distribution for these values
    res.rep[i] <- y.rep[i]-mu[i]
    stdres.rep[i] <- res.rep[i]*sqrt(tau)
    
    dev1.rep[i] <- pow(res.rep[i],2)
    dev2.rep[i] <- pow(stdres.rep[i],2)
    
    # Likelihood for each observed and replicated data
    # note: Need to know the density function of the probability model
    
    loglike[i] <- (0.5)*log(tau/6.283185) + (-0.5)*tau*pow((y[i]-mu[i]),2)
    loglike.rep[i]<-  (0.5)*log(tau/6.283185) + (-0.5)*tau*pow((y.rep[i]-mu[i]),2)
    
    p.inv[i]<- 1/exp(loglike[i])      #  This is to find the predictive ordinate of the observations
  }
  
  # Prior definitions
  b[1]~dnorm(0,.000001)
  b[2]~dnorm(0,.000001)
  tau~dgamma(.0001,.0001)

  # Summing Diagnostics Values
  chidev1.obs <- sum(dev1.obs[])
  chidev2.obs <- sum(dev2.obs[])

  chidev1.rep <- sum(dev1.rep[] )
  chidev2.rep <- sum(dev2.rep[] )

  chidev1.pval<-step(chidev1.obs-chidev1.rep)
  chidev2.pval<-step(chidev2.obs-chidev2.rep)

  #   Deviance statistic
  dev<-   -2*sum(loglike[])
  dev.rep <-  -2*sum(loglike.rep[])
  dev.pval<-step(dev-dev.rep)

}", file="HarvestModQ21.txt")


# Setup Parameters
bugMQ21.dat<-list("x", "y", "N")

initMQ21.fun<-function(){ list(b=runif(2,-.8,-.2), tau=runif(1,.2,.8), y.rep=rnorm(N))} 

paramsMQ21<-c("b", "tau",          # the rest are for the model checking
              "mu", "res", "stdres", "res.rep", "stdres.rep", "p.smaller",
              "p.inv", "chidev1.pval", "chidev2.pval", "chidev1.obs", "chidev2.obs",
              "chidev1.rep", "chidev2.rep", "dev", "dev.rep", "dev.pval")


#### Could change the code below...
# Run Open Bugs - 
set.seed(2157)
attach(HarvestingData)
HarvestingMQ21=bugs(bugMQ21.dat, initMQ21.fun, paramsMQ21, model.file="HarvestModQ21.txt",
                    n.chains=NChain, n.iter=NSim, n.burnin=Burnin, n.thin=NThin)
detach(HarvestingData)


# Get Simulation from OpenBugs
SArrayMQ21= HarvestingMQ21$sims.array   # Data Arrays
vname=attr(SArrayMQ21,"dimnames")[3][[1]]  # Variable Names
MQ21.coda <- as.mcmc.list(HarvestingMQ21)


# Print Summary statistics of parameters oif Interest
RNames <- rownames(HarvestingMQ21[["summary"]][,c(1:3,5,7)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(HarvestingMQ21[["summary"]][,c(1:3,5,7)]))
df_Prt %>%
  filter(substr(Parameter,1,2)=="b[" |
           substr(Parameter,1,3)=="tau") %>% 
  kbl(booktabs = TRUE, digits = 4,
      caption = "OpenBugs Summary - Harvesting Date vs. Yield (Model-1)") %>% 
  kable_styling(latex_options = "striped")

# Plot TracePlots * b[1], b[2] and tau *

# Sampling 5000 points to generate "thinner" traceplots
set.seed(312)

L <- NSim-Burnin

#OldSz <- Sz  
#Sz <- L       # Override Original value

S <- if (Sz < L) sort(sample(1:L, Sz, replace = FALSE)) else 1:Sz

# Build working dataframe
D_Workb1<- data.frame(ValCh1=SArrayMQ21[S,1,paste0("b[1]")],
                      ValCh2=SArrayMQ21[S,2,paste0("b[1]")],
                      ValCh3=SArrayMQ21[S,3,paste0("b[1]")])

D_Workb2 <- data.frame(ValCh1=SArrayMQ21[S,1,paste0("b[2]")],
                       ValCh2=SArrayMQ21[S,2,paste0("b[2]")],
                       ValCh3=SArrayMQ21[S,3,paste0("b[2]")])

D_Worktau <- data.frame(ValCh1=SArrayMQ21[S,1,paste0("tau")],
                        ValCh2=SArrayMQ21[S,2,paste0("tau")],
                        ValCh3=SArrayMQ21[S,3,paste0("tau")])

# Plot Traceplots for selected data-frames
P1 <- D_Workb1 %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta[1])) +
  theme_bw()
P2 <- D_Workb2 %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta[2])) +
  theme_bw()
P3 <- D_Worktau %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(tau)) +
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)

# Remove Working Variable to free memory
# Sz <- OldSz # Restore original value
remove(D_Workb1, D_Workb2, D_Worktau )

# Plot ACF Plots * b[1], b[2] and tau *

# Build working dataframe
D_Workb1 <- data.frame(ValCh1=SArrayMQ21[,1,paste0("b[1]")])
D_Workb2 <- data.frame(ValCh1=SArrayMQ21[,1,paste0("b[2]")])
D_Worktau <- data.frame(ValCh1=SArrayMQ21[,1,paste0("tau")])

# Plot ACF Plots for selected data-frames
P1 <- ggAcf(D_Workb1$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(beta[1])) +
  ggtitle(NULL)+
  theme_bw()
P2 <- ggAcf(D_Workb2$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(beta[2])) +
  ggtitle(NULL)+
  theme_bw()
P3 <- ggAcf(D_Worktau$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(tau)) +
  ggtitle(NULL)+
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)
# Remove Working Variable to free memory
remove(D_Workb1, D_Workb2, D_Worktau )

# MODEL Q2_2
cat("### Model 2 -
model{
  for (i in 1:N) {
    y[i]~dnorm(mu[i],tau)
    mu[i]<- b[1] + b[2]*(x[i]-31)+ b[3]*pow((x[i]-31),2)
 
    # Get the residuals for the observed value
    res[i] <- (y[i]-mu[i])           # Estimate the residual for this model  - Item (1)
    stdres[i] <- res[i]*sqrt(tau)    # Calculate the standard residuals - Item (2)
    
    dev1.obs[i] <- pow(res[i],2)
    dev2.obs[i] <- pow(stdres[i],2)
    
    # Get a replicated Sample - sample of the predictive distribution
    y.rep[i]~dnorm(mu[i],tau)
    p.smaller[i] <- step(y[i]-y.rep[i])  # Check to see the probability of getting extreme value - Item (3)
    
    # Residual and Moments replicated - this gives the predicted distribution for these values
    res.rep[i] <- y.rep[i]-mu[i]
    stdres.rep[i] <- res.rep[i]*sqrt(tau)
    
    dev1.rep[i] <- pow(res.rep[i],2)
    dev2.rep[i] <- pow(stdres.rep[i],2)
    
    # Likelihood for each observed and replicated data
    # note: Need to know the density function of the probability model
    
    loglike[i] <- (0.5)*log(tau/6.283185) + (-0.5)*tau*pow((y[i]-mu[i]),2)
    loglike.rep[i]<-  (0.5)*log(tau/6.283185) + (-0.5)*tau*pow((y.rep[i]-mu[i]),2)
    
    p.inv[i]<- 1/exp(loglike[i])      #  This is to find the predictive ordinate of the observations
  }
  
  # Prior definitions
  b[1]~dnorm(0,.000001)
  b[2]~dnorm(0,.000001)
  b[3]~dnorm(0,.01)
  tau~dgamma(.0001,.0001)

  # Summing Diagnostics Values
  chidev1.obs <- sum(dev1.obs[])
  chidev2.obs <- sum(dev2.obs[])

  chidev1.rep <- sum(dev1.rep[] )
  chidev2.rep <- sum(dev2.rep[] )

  chidev1.pval<-step(chidev1.obs-chidev1.rep)
  chidev2.pval<-step(chidev2.obs-chidev2.rep)

  #   Deviance statistic
  dev<-   -2*sum(loglike[])
  dev.rep <-  -2*sum(loglike.rep[])
  dev.pval<-step(dev-dev.rep)

}", file="HarvestModQ22.txt")

# Setup Parameters
paramsMQ22 <- c("b", "tau",          # the rest are for the model checking
                "mu", "res", "stdres", "res.rep", "stdres.rep", "p.smaller",
                "p.inv", "chidev1.pval", "chidev2.pval", "chidev1.obs", "chidev2.obs",
                "chidev1.rep", "chidev2.rep", "dev", "dev.rep", "dev.pval")

bugMQ22.dat=list("x", "y", "N")  # what variable you need in the model

# Setup Initial Values
initMQ22.fun=function(){ 
  list(b=runif(3,-.8,-.2), tau=runif(1,.2,.8), y.rep=rnorm(N)) 
}

#### Run Openbugs Simulation
set.seed(3508)
attach(HarvestingData)
HarvestingMQ22=bugs(bugMQ22.dat, initMQ22.fun, paramsMQ22, model.file="HarvestModQ22.txt",
                    n.chains=NChain, n.iter=NSim, n.burnin=Burnin, n.thin=NThin , debug=FALSE)
detach(HarvestingData)


# Get Simulation from OpenBugs
SArrayMQ22= HarvestingMQ22$sims.array   # Data Arrays
vname=attr(SArrayMQ22,"dimnames")[3][[1]]  # Variable Names
MQ22.coda <- as.mcmc.list(HarvestingMQ22)


# Print Summary statistics of parameters oif Interest
RNames <- rownames(HarvestingMQ22[["summary"]][,c(1:3,5,7)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(HarvestingMQ22[["summary"]][,c(1:3,5,7)]))
df_Prt %>%
  filter(substr(Parameter,1,2)=="b[" |
           substr(Parameter,1,3)=="tau") %>% 
  kbl(booktabs = TRUE, digits = 4, 
      caption = "OpenBugs Summary - Harvesting Date vs. Yield (Model-2)") %>% 
  kable_styling(latex_options = "striped")

# Plot TracePlots * b[1], b[2], b[3] and tau *

# Sampling 5000 points to generate "thinner" traceplots
set.seed(792)

L <- NSim-Burnin

S <- if (Sz < L) sort(sample(1:L, Sz, replace = FALSE)) else 1:Sz

# Build working dataframe
D_Workb1<- data.frame(ValCh1=SArrayMQ22[S,1,paste0("b[1]")],
                      ValCh2=SArrayMQ22[S,2,paste0("b[1]")],
                      ValCh3=SArrayMQ22[S,3,paste0("b[1]")])

D_Workb2 <- data.frame(ValCh1=SArrayMQ22[S,1,paste0("b[2]")],
                       ValCh2=SArrayMQ22[S,2,paste0("b[2]")],
                       ValCh3=SArrayMQ22[S,3,paste0("b[2]")])

D_Workb3 <- data.frame(ValCh1=SArrayMQ22[S,1,paste0("b[3]")],
                       ValCh2=SArrayMQ22[S,2,paste0("b[3]")],
                       ValCh3=SArrayMQ22[S,3,paste0("b[3]")])

D_Worktau <- data.frame(ValCh1=SArrayMQ22[S,1,paste0("tau")],
                        ValCh2=SArrayMQ22[S,2,paste0("tau")],
                        ValCh3=SArrayMQ22[S,3,paste0("tau")])

# Plot Traceplots for selected data-frames
P1 <- D_Workb1 %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta[1])) +
  theme_bw()
P2 <- D_Workb2 %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta[2])) +
  theme_bw()
P3 <- D_Workb3 %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta[3])) +
  theme_bw()
P4 <- D_Worktau %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(tau)) +
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)

# Remove Working Variable to free memory
remove(D_Workb1, D_Workb2, D_Workb3, D_Worktau )

# Plot ACF Plots * b[1], b[2], b[3] and tau *

# Build working dataframe
D_Workb1 <- data.frame(ValCh1=SArrayMQ22[,1,paste0("b[1]")])
D_Workb2 <- data.frame(ValCh1=SArrayMQ22[,1,paste0("b[2]")])
D_Workb3 <- data.frame(ValCh1=SArrayMQ22[,1,paste0("b[3]")])
D_Worktau <- data.frame(ValCh1=SArrayMQ22[,1,paste0("tau")])

# Plot ACF Plots for selected data-frames
P1 <- ggAcf(D_Workb1$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(beta[1])) +
  ggtitle(NULL)+
  theme_bw()
P2 <- ggAcf(D_Workb2$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(beta[2])) +
  ggtitle(NULL)+
  theme_bw()
P3 <- ggAcf(D_Workb3$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(beta[3])) +
  ggtitle(NULL)+
  theme_bw()
P4 <- ggAcf(D_Worktau$ValCh1, lag.max = 50)+
  labs(x = "Lag", y = expression(tau)) +
  ggtitle(NULL)+
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)
# Remove Working Variable to free memory
remove(D_Workb1, D_Workb2, D_Workb3, D_Worktau )

# Routines to Calculate DIC, Deviance of Model - Author: Michael Escobar (Thanks!)

# OBS>:- Flow remodeled to document each step

# Calculates the Deviance by hand
devNormFunc <- function(beta0, beta1, beta2, tau, x, y) {
  mu <- beta0 + beta1*x + beta2*x^2
  return(-2*sum(log(dnorm(y,mu,1/sqrt(tau)))))
}

CalcModelStats <- function (Model, TxtModel) {
  
  # STEP 1 - Calculate the Likelihood and respective Inverse
  M1.pinv <- Model$mean$p.inv       # Get 1/p(x)
  PLogLI <- -1*log(M1.pinv)                  # Get p(x)
  
  # Collects Inv.p(x) Likelihood, P[Log(Likelihood)]
  TbWork1 <- cbind(M1.pinv,1/M1.pinv,PLogLI)
  colnames(TbWork1) <- c("p.inv","p(x)","PLogLI");#TbWork1
  Pseudom2logL= -2*sum(PLogLI);#Pseudom2logL
  #cat("\n-------------------\n\n")
  
  # Collect Residuals (TbWork2)
  TbWork2<-cbind(Model$mean$res,
                 t(apply(Model$sims.list$res.rep,2,
                         function(x){c(quantile(x,probs=c(0.025,.975)),mean(x),sd(x))})))
  colnames(TbWork2)=c("res","2.5%","97.5%","mean","SD");#TbWork2
  #cat("\n-------------------\n\n")
  
  # Collect Std.Residuals (TbWork3)
  TbWork3<-cbind(Model$mean$stdres,
                 t(apply(Model$sims.list$stdres.rep,2,
                         function(x){c(quantile(x,probs=c(0.025,.975)),mean(x),sd(x))})))
  colnames(TbWork3)=c("stdres","2.5%","97.5%","mean","SD");#TbWork3
  #cat("\n-------------------\n\n")
  
  # Collect Deviance (TbWork4)
  M1.devrep<-Model$sims.list$dev.rep
  TbWork4<-c(Model$mean$dev,
             quantile(M1.devrep,probs=c(0.025,.975)),
             mean(M1.devrep),sd(M1.devrep))
  names(TbWork4)=c("Deviance","2.5%","97.5%","mean","SD");#TbWork4
  #cat("\n-------------------\n\n")
  
  # Collect Chi-Deviance (TbWork5)
  M1.chidev2rep<-Model$sims.list$chidev2.rep
  TbWork5<-c(Model$mean$chidev2.obs,
             quantile(M1.chidev2rep,probs=c(0.025,.975)),
             mean(M1.chidev2rep),sd(M1.chidev2rep))
  names(TbWork5)=c("Chi-Dev2","2.5%","97.5%","mean","SD");#TbWork5
  #cat("\n-------------------\n\n")
  
  # Calculates Non-Calibrated ("pval-stats") - REVIEW - 
  #apply(Model$sims.list$p.smaller,2,mean)
  #Model$mean$chidev2.pval
  #Model$mean$dev.pval
  #cat("\n-------------------\n\n")
  
  # Comparing intrinsic and self calculated value for Deviance:
  M1.dev <-Model$sims.list$dev
  M1.deviance <-Model$sims.list$deviance
  TbWork6 <-rbind(
    quantile(M1.dev,probs=c(0.025,.25,.5,.75,.975)),
    quantile(M1.deviance,probs=c(0.025,.25,.5,.75,.975)) )
  rownames(TbWork6)=c("SelfProgramed:","Openbugs Made:");# TbWork6    
  # cat("\n-------------------\n\n")
  
  # c(Model$mean$deviance,Model$mean$dev)    
  Dbar<-mean(M1.dev);#Dbar   # Calculated - Deviance 
  pd2<-0.5*var(M1.dev);#pd2
  
  
  # Setup Parameters for Model
  beta0Bar<- Model$mean$b[1]
  beta1Bar<- Model$mean$b[2]
  beta2Bar<- ifelse (dim(Model$sims.list$b)[2]==3,Model$mean$b[3],0)
  tauBar <- Model$mean$tau
  Dhat <- devNormFunc(beta0Bar, beta1Bar, beta2Bar, tauBar, 
                      HarvestingData$x,HarvestingData$y);#Dhat 
  pd1<-Dbar-Dhat;#pd1
  
  DIC1<-Dbar+pd1; #DIC1
  DIC2<-Dbar+pd2; #DIC2
  
  
  cat("\n------- Goodness of Fit Statistics for",TxtModel," --------")
  cat("\nDeviance: \n");
  print(TbWork6, dig=4)
  cat("\nDbar: ",format(Dbar, digits = 2, nsmall = 4))
  # cat("\nDhat: ",format(Dhat, digits = 2, nsmall = 4))
  cat("\npD:  ",format(pd2, digits = 2, nsmall = 4))
  cat("\nDIC: ",format(DIC2, digits = 2, nsmall = 4))
  cat("\n--------------------------------------------------------\n")
}


CalcModelStats(HarvestingMQ21,"Model-1")
CalcModelStats(HarvestingMQ22,"Model-2")

# Setup for Kuo-Mallick Model Variables - LAST VERSION

# Mean and Variance of Y
mu_y <- mean(HarvestingData$y)
sd_y <- sd(HarvestingData$y)

# Mean and Variance of X
mu_x <- mean(HarvestingData$x)
sd_x <- sd(HarvestingData$x)

# Mean and Variance of X^2
mu_x2 <- mean(HarvestingData$x^2)
sd_x2 <- sd(HarvestingData$x^2)

pp <- 0.5

# OBS:- I tested 'tau0' with several values and all decided in favor of M2 (which makes perfectly sense!) 
#       I ended up choosing a value inside the interval of 1/16<tau0<4
tau0 <- 0.3

# Standardizing Variables X and Y
sx <- (HarvestingData$x-mu_x)/sd_x          # Standardized X
sx2 <- (HarvestingData$x^2-mu_x2)/sd_x2     # Standardized X^2
sy <- (HarvestingData$y-mu_y)/sd_y          # Standardized y

cat("### Kuo-Mallick Model Selection
model{
  for (i in 1:N) {
    sy[i]~dnorm(mu[i],tau)
    mu[i]<- delta[1]*beta[1]*sx[i] + delta[2]*beta[2]*sx2[i]
  }
  
  for (ix in 1:2) {
    beta[ix]~dnorm(0,tau0)
  }
  
  tau~dgamma(.5,.01) 
  
  # Prior Distribution of delta[]
  for(k in 1:2){
    delta[k]~dbern(pp)
  }
  
  # Model Deltas
  for(i1 in 1:2){
    for(i2 in 1:2){
      mod[i1,i2]<-equals((2-i1),delta[1])*equals((2-i2),delta[2])
     }
  }

}", file="Harvest_KM.txt")

dataDiag_KM<-list("sx", "sy", "mu_y", "sd_y", "N",
                  "mu_x", "sd_x", "pp", "tau0")

initsDiag_KM<-function(){ list(beta=rnorm(2), tau=runif(1,.5,1))}

paramDiag_KM<-c("beta", "tau", "delta", "mod")


set.seed(9212)
attach(HarvestingData)

HarvestDiag_KM<-bugs(dataDiag_KM,initsDiag_KM, paramDiag_KM, model.file="Harvest_KM.txt",
                     n.chains=1, n.iter=20000, n.burnin=5000,
                     n.thin=10)
detach(HarvestingData)


# Calculus of abeta[]'s
abeta1 <- HarvestDiag_KM$sims.array[,,paste0("beta[1]")]*sd_x/sd_y
abeta2 <- HarvestDiag_KM$sims.array[,,paste0("beta[2]")]*sd_x/sd_y

t_abeta1 <- c(mean(abeta1),sd(abeta1),quantile(abeta1,c(.025,.5,.975)))
t_abeta2 <- c(mean(abeta2),sd(abeta2),quantile(abeta2,c(.025,.5,.975)))

abeta <- rbind(t_abeta1,t_abeta2)
colnames(abeta) <- c("mean","sd","2.5%","50%","97.5%")
rownames(abeta) <- c("abeta[1]","abeta[2]")

# Print Summary statistics of parameters oif Interest
RNames <- rownames(HarvestDiag_KM[["summary"]][,c(1:3,5,7)]) # List of parameters
df_KM <- data.frame(Parameter = RNames)
df_KM <- cbind(df_KM, as_tibble(HarvestDiag_KM[["summary"]][,c(1:3,5,7)]))
df_KM %>%
  kbl(booktabs = TRUE, digits = 4,
      caption = "OpenBugs Summary - Kuo-Mallik Model Selection Statistics") %>% 
  kable_styling(latex_options = "striped")

# Jeffrey's Criteria for Bayes Factor
JeffCrit <- function(BF) {
  if (BF>=0.0 && BF<=.5) return("Not worth more than a bare mention")
  else{
    if (BF>.5 && BF<=1.0) return("Substantial")
    else {
      if (BF>1.0 && BF<=2.0) return("Strong")
      else return("Decisive")
    }
  }
}

# Kass, Raftery's Criteria for Bayes Factor
KassRafteryCrit <- function(BF) {
  if (BF>=0.0 && BF<=2.0) return("Not worth more than a bare mention")
  else{
    if (BF>2.0 && BF<=6.0) return("Positive")
    else {
      if (BF>6.0 && BF<=10.0) return("Strong")
      else return("Decisive")
    }
  }
}

Kuo_MallickCrit <- function(PModA, PModB, TxtModA, TxtModB) {
  BF_KM <- PModA/PModB
  # Print Kuo-Mallik Bayes Factor Analysis for Model-A over Model-B
  cat("\n-------- Kuo-Mallik Bayes Factor Analysis (",TxtModA,"/",TxtModB,") ---------")
  cat("\n\nPosterior Probability",TxtModA,"| Data: ",format(PModA, digits = 2, nsmall = 4))
  cat("\n\nPosterior Probability",TxtModB,"| Data: ",format(PModB, digits = 2, nsmall = 4))
  cat("\n\n>>> Bayes Factor : ",format(BF_KM, digits = 2, nsmall = 4))
  cat("\n\n>>> Jeffrey's Evidence of",TxtModA,"over",TxtModB,": ",JeffCrit(log10(BF_KM)))
  cat("\n\n>>> Kass/Raftery's Evidence of",TxtModA,"over",TxtModB,": ",KassRafteryCrit(2*log(BF_KM)))
  cat("\n---------------------------------------------------------------\n")
}


# Calculation of BF - It is equivalent to compare
#    mod[1,1] (Model-2) agains mod[1,2] (Model-1)
PM1 <- df_KM[which(df_KM$Parameter=="mod[1,2]"),"mean"]#;PM1  # This is Probability of Model-1
PM2 <- df_KM[which(df_KM$Parameter=="mod[1,1]"),"mean"]#;PM2  # This is Probability of Model-2

Kuo_MallickCrit (PM2, PM1, "M2", "M1")

# Item (1) - Print Residuals
RNames <- rownames(HarvestingMQ21[["summary"]][,c(1:3,5,7)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(HarvestingMQ21[["summary"]][,c(1:3,5,7)]))
df_Prt %>%
  filter(substr(Parameter,1,4)=="res[") %>% 
  kbl(booktabs = TRUE, digits = 4,
      caption = "OpenBugs Summary - Residuals for Model-1") %>% 
  kable_styling(latex_options = "striped")

# Item (2) - Print Standardized Residuals
RNames <- rownames(HarvestingMQ21[["summary"]][,c(1:3,5,7)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(HarvestingMQ21[["summary"]][,c(1:3,5,7)]))
df_Prt %>%
  filter(substr(Parameter,1,7)=="stdres[") %>% 
  kbl(booktabs = TRUE, digits = 4,
      caption = "OpenBugs Summary - Standardized Residuals for Model-1") %>% 
  kable_styling(latex_options = "striped")

# Item (3) - Print Chance of Getting Extreme Observations
RNames <- rownames(HarvestingMQ21[["summary"]][,c(1:2)]) # List of parameters
df_Prt <- data.frame(Parameter = RNames)
df_Prt <- cbind(df_Prt, as_tibble(HarvestingMQ21[["summary"]][,c(1:2)]))
df_Prt %>%
  filter(substr(Parameter,1,10)=="p.smaller[") %>% 
  kbl(booktabs = TRUE, digits = 4,
      caption = "OpenBugs Summary - Chance of Extreme Observations for Model-1") %>% 
  kable_styling(latex_options = "striped")

# Get Distribution of Residuals/Std Residuals under Predictive Distribution
SArrayDiagM1= HarvestingMQ21$sims.array      # Data Arrays
vname=attr(SArrayDiagM1,"dimnames")[3][[1]]  # Variable Names


# Plot Sample densities to Compare Distributions of Residuals

# Build working dataframe
D_WorkRes <- as_tibble(data.frame(LvlStd=as.vector(
  SArrayDiagM1[,1,c(paste0("res.rep[", 1:16, "]"))]), Chain = "C1"))
D_WorkstdRes <- as_tibble(data.frame(LvlStd=as.vector(
  SArrayDiagM1[,1,c(paste0("stdres.rep[", 1:16, "]"))]), Chain = "C1"))

# Ploting the Sensities
P1 <- D_WorkRes %>%
  ggplot(aes(x = LvlStd))+
  geom_density(aes(x=LvlStd, group=Chain, colour=Chain), size=0.8)+ 
  labs(x = "Residuals", y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()
P2 <- D_WorkstdRes %>%
  ggplot(aes(x = LvlStd))+
  geom_density(aes(x=LvlStd, group=Chain, colour=Chain), size=0.8)+ 
  labs(x = "Std.Residuals", y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

ggpubr::ggarrange(P1+theme(legend.position="none"), 
                  P2+theme(legend.position="none"), ncol = 1, nrow = 2)
remove(D_WorkRes,D_WorkstdRes)

# Sample points for Residuals
set.seed(792)
LR <-  length(SArrayDiagM1[,1,c(paste0("res.rep[", 1:16, "]"))])
S <- sort(sample(1:LR, 30000, replace = FALSE))

# Build working dataframe
D_WorkRes <- rbind(
  data.frame(
    Iter = c(1:length(S)),
    Res=as.vector(
      SArrayDiagM1[,1,c(paste0("res.rep[", 1:16, "]"))][S]), Model = "M1"),
  data.frame(
    Iter = c(1:length(S)),
    Res=as.vector(
      SArrayDiagM2[,1,c(paste0("res.rep[", 1:16, "]"))][S]), Model = "M2"))

# Ploting Residuals
D_WorkRes %>%
  ggplot(aes(x=Iter))+
  geom_point(aes(y=Res, colour=Model), size=0.6)+ 
  labs(x = "Iteration", y = "Residual") +
  scale_color_manual(values = cbp2)+
  theme_bw()

remove(D_WorkRes)

# Sample points for Residuals
set.seed(792)
LR <-  length(SArrayDiagM1[,1,c(paste0("res.rep[", 1:16, "]"))])
S <- sort(sample(1:LR, 30000, replace = FALSE))

# Build working dataframe
D_WorkRes <- rbind(
  data.frame(
    Iter = c(1:length(S)),
    Res=as.vector(
      SArrayDiagM1[,1,c(paste0("res.rep[", 1:16, "]"))][S]), Model = "M1"),
  data.frame(
    Iter = c(1:length(S)),
    Res=as.vector(
      SArrayDiagM2[,1,c(paste0("res.rep[", 1:16, "]"))][S]), Model = "M2"))

# Calculate Absolute Error for each model
D_WorkAbsErr <- rbind(
  data.frame(
    Iter = c(1:length(S)),
    AbsErr=as.vector(SArrayDiagM1[,1,c(paste0("res.rep[", 1:16, "]"))][S])/LR, Model = "M1"),
  data.frame(
    Iter = c(1:length(S)),
    AbsErr=as.vector(SArrayDiagM2[,1,c(paste0("res.rep[", 1:16, "]"))][S])/LR, Model = "M2"))

# Calculate Relative Error for each model
D_WorkRelErr <- rbind(
  data.frame(
    Iter = c(1:length(S)),
    RelErr=as.vector(SArrayDiagM1[,1,c(paste0("res.rep[", 1:16, "]"))][S]/
                       SArrayDiagM1[,1,c(paste0("mu[", 1:16, "]"))][S]), Model = "M1"),
  data.frame(
    Iter = c(1:length(S)),
    RelErr=as.vector(SArrayDiagM2[,1,c(paste0("res.rep[", 1:16, "]"))][S]/
                       SArrayDiagM2[,1,c(paste0("mu[", 1:16, "]"))][S]), Model = "M2"))

# Ploting Residuals
D_WorkRes %>%
  ggplot(aes(x=Iter))+
  geom_point(aes(y=Res, colour=Model), size=0.6)+ 
  labs(x = "Iteration", y = "Residual") +
  scale_color_manual(values = cbp2)+
  theme_bw()

# Ploting Absolute error
P2 <- D_WorkAbsErr %>%
  ggplot(aes(x=Iter))+
  geom_point(aes(y=AbsErr, colour=Model), size=0.6)+ 
  labs(x = "Iteration", y = "Absolute Error") +
  scale_color_manual(values = cbp2)+
  theme_bw()

# Ploting Relative error
P3 <- D_WorkRelErr %>%
  ggplot(aes(x=Iter))+
  geom_point(aes(y=RelErr, colour=Model), size=0.6)+ 
  labs(x = "Iteration", y = "Relative Error") +
  scale_color_manual(values = cbp2)+
  theme_bw()

ggpubr::ggarrange(P2+theme(axis.title.x=element_blank()), 
                  P3+theme(axis.title.x=element_blank()), ncol = 1, nrow = 2)


remove(D_WorkAbsErr, D_WorkRelErr, D_WorkRes)

```

