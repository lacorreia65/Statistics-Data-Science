---
title: "CHL5223 - Applied Bayesian Methods - Assignment 4"
author: "Luis Correia - Student No. 1006508566"
date: "April 6th 2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
  rmarkdown::pdf_document:
    fig_caption: yes
    number_sections: yes
header-includes:
- \usepackage[margin=1in]{geometry} 
- \usepackage{amsmath,amsthm,amssymb,amsfonts}
- \usepackage{relsize}
- \usepackage{lscape}
- \usepackage{enumerate}
- \usepackage{enumitem}
- \usepackage{setspace}
- \usepackage{tikz}
- \usepackage{bm}
- \usepackage{bbm}
- \usepackage[utf8]{inputenc}
- \usepackage{mathtools, nccmath}
- \usepackage{fancyhdr}
- \usepackage{float}
- \usepackage[linesnumbered,vlined,ruled,commentsnumbered]{algorithm2e}
- \floatplacement{figure}{H}
- \floatplacement{table}{H}
- \pagestyle{fancy}
- \fancyhead[CO,CE]{---CHL5223 - Applied Bayesian Methods---}
- \fancyfoot[C]{Luis Correia - Student No. 1006508566}
- \fancyfoot[RO, LE] {\thepage}
- \setlength{\parskip}{1em}
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, fig.width=5, fig.height=4.0)
```

```{r, warning=FALSE, echo=FALSE}
library(tidyverse)
library(R2OpenBUGS)
library(kableExtra)
library(coda)

```

```{r}
library(ggplot2)
library(forecast)

# The palette with black - Used in Graphs with :
cbp1 <- c("#999999", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbp2 <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbp3 <- c("#FFDB6D", "#C4961A", "#F4EDCA", "#D16103", 
          "#C3D7A4", "#52854C", "#4E84C4", "#293352")
```


\maketitle

\section{Question 1}

Simulating random variables
 
\textbf{Introduction}: For this problem, you are required to estimate the mean and variance for a random variable using some of the methods discussed in class. Consider a random variable X with density g(x). For each of the questions below, you are allowed to get random uniform variables using the R command \texttt{runif}. Also, you are just allowed to sample a total of $1000$ uniform random variables. In each question, you will use a different technique which is described in the notes. For a complete answer, you should not simple provide the numeric value for your calculation. You need to describe why the algorithm you used is the correct algorithm.

\textbf{Details of the random variable}: Let $X$ be a sample from the triangle distribution. That is, if $g(x)$ is the density function for $X$, then define $g(x)$ as:


\begin{equation}
    g(x) =
    \begin{cases}
      4x, & \text{for }0.0 \le x \le 0.5\\
      4-4x, & \text{for }0.5 < x \le 1.0\\
      0, & \text{otherwise}\label{eq1_0}
    \end{cases}
\end{equation}

In the plot, this density is the solid line. Note, you could define the function $g(x)$ in R as:

\texttt{g=function(x){(x>0)*(x<1)*((x<=0.5)*4*x+ (x>0.5)*(4-4*x))}}

Also, let f(x) be the density function for the uniform distribution from 0 to 1. Then, $f(x)$ is defined as:

\begin{equation}
    f(x) =
    \begin{cases}
      1, & \text{for }0 \le x \le 1\\
      0, & \text{otherwise}\label{eq1_1}
    \end{cases}
\end{equation}

In the plot, this density is the dashed line. Note that $2f(x)\ge g(x)$.


\subsection{item (a)}

Let $U_1$ and $U_2$ be two independent samples from a uniform distribution on $[0,1]$. Define a sample random variable $Z$ by $(U_1+U_2)/2$. Note that Z is then a random sample from the triangle distribution and has density function $g$. Create a series of independent $Z_i$'s in this manner in order to estimate $\mathbb{E}(X)$ and $\mathbb{V}ar(X)$.

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

For these item the algorithm we will use is just generate the a new variable $Z$ defined by $Z=\dfrac{U_1+U_2}{2}$ with $U_1, U_2\sim Unif[0,1]$ to estimate $\mathbb{E}(X)$ and $\mathbb{V}ar(X)$ - details of implementation can be found on \textbf{Appendix}. 

\medskip

We have obtained  the following results: 


```{r}
# Triangular Distribution
g=function(x){
  (x>0)*(x<1)*((x<=0.5)*4*x+ (x>0.5)*(4-4*x))
}

# Set parameters
N = 1000

set.seed(123)

# Generating two independent samples U1 and U2 from Uniform[0,1]
U1 <- runif(N)
U2 <- runif(N)

# Calculating the exact distribution of Z:= (U1+U2)/2
Z <- (U1+U2)/2

# Estimate E(X) and E(Y) Considerin that Z ~Triang(g)
EZ <- mean(Z)
VarZ <- var(Z)
SE_Z <- sd(Z)/sqrt(N)

# Print Statistics for Approx. Z
cat("\n---- Summary Statistics for approx. Z=(U1+U2)/2 ---------------")
cat("\nE(X) : ",format(EZ, digits = 2, nsmall = 4)) 
cat("\nS.E.: ",format(SE_Z, digits = 5, nsmall = 4))
CR_Z_up <- EZ+2*SE_Z; CR_Z_lo <- EZ-2*SE_Z; 
cat("\n\n95% Credible Region for true-Mean (", 
    format(CR_Z_lo, digits = 6, nsmall = 4), ",",
    format(CR_Z_up, digits = 6, nsmall = 4),")\n")
cat("\nVar(X) : ",format(VarZ, digits = 5, nsmall = 4)) 
cat("\n---------------------------------------------------------------\n")

```

The histogram of the samples obtained by this method is as follows:

```{r, fig.cap= "Histogram of simulated Z", fig.width=4.5, fig.height=3.8}
dfz <- data.frame (ZS = Z)
ggplot(data=dfz, aes(x=ZS))+
  geom_histogram(color="black", fill="white", bins=40)+
  scale_color_manual(values = cbp2)+
  labs(x = "g(.) sample", y = "Histogram of Z")+
  theme_bw()
remove(dfz)
```

\subsection{item (b)}

Just using sample from a uniform distribution on $[0,1]$, use the importance sampler method. That is, do the following:
\begin{itemize}
    \item i. Provide the weight function for the importance sampler when using sampled values from the uniform distribution.
    \item ii. Give the estimates for $\mathbb{E}(X)$ and $\mathbb{V}ar(X)$. (Note: $\mathbb{V}ar(X) = \mathbb{E}(X^2) - [\mathbb{E}(X)^2]$.)
\end{itemize}

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

Using the \textit{Importance Sampling} method the \textit{weight function} used was:

\begin{equation}
    w(U_i)=g(U_i)/f(U_i)\text{, for }i=1,\dots,N\label{eq1b_01}
\end{equation}

... where $U_i\sim Unif[0,1]$ and $g(\cdot)$ is the \textit{density function of the triangular distribution} defined in \eqref{eq1_0} and $f(\cdot)$ defined in \eqref{eq1_1}.

This algorithm perfoms the estimation of $\mathbb{E}(X)$ via \textit{Monte Carlo Integration Estimation}, and we can use the same approach to estimate the 2nd. momentum of $X$ and then estimate $\mathbb{V}ar(X)$ - details of implementation can be found on \textbf{Appendix}. 

\medskip

We obtained the following results for estimates to $\mathbb{E}(X)$ and $\mathbb{V}ar(X)$:

```{r}
# Item (b) - here h_1(X) = X => h_1(U3)=U3
set.seed(725)
U3 <- runif(N)

# Estimate E(X) via Importance Sampling 
EX_IS <- (1/N)*sum((U3*g(U3))/(1))

# here h_2(X) = X^2 => h_1(U3)=U3^2
EX_IS2 <- (1/N)*sum((U3^2*g(U3))/(1))
VarX_IS <- EX_IS2-EX_IS^2
SE_IS <- sd((U3*g(U3))/(1))/sqrt(N)

# Print Statistics for Importance Sampling
cat("\n---- Summary Statistics for Importance Sampling Algorithm -----")
cat("\nE(X) : ",format(EX_IS, digits = 2, nsmall = 4)) 
cat("\nS.E.: ",format(SE_IS, digits = 5, nsmall = 4))
CR_IS_up <- EX_IS+2*SE_IS; CR_IS_lo <- EX_IS-2*SE_IS; 
cat("\n\n95% Credible Region for true-Mean (", 
    format(CR_IS_lo, digits = 6, nsmall = 4), ",",
    format(CR_IS_up, digits = 6, nsmall = 4),")\n")
cat("\nVar(X) : ",format(VarX_IS, digits = 5, nsmall = 4)) 
cat("\n---------------------------------------------------------------\n")

```

As importance Sampling doesn't actually simulates a random variable distribution but consists in a \textit{Monte Carlo Integration} method, we will skip from providing an histogram of simulated data in this case. Nonetheless, just for fun, we can estimate the error when calculating the integral under the density function $g(\cdot)$ which we expect to get a value close to $1$, as $N$ increases.

```{r, warning=FALSE, fig.cap= "Estimated Density Integration obtained from Importance Sampling", fig.width=5.5, fig.height=4.5}

# Adapted from Robert, Casella - pp.66
xx=g(U3)
mxx <- mean(xx)
estint=cumsum(xx)/(1:N)
esterr=sqrt(cumsum((xx-estint)^2))/(1:N)
dxx <- data.frame(yest = estint,
                  low = estint-2*esterr,
                  up = estint+2*esterr)
ggplot(data=dxx, aes(x=c(1:N)))+
  geom_line(aes(y=yest), size=0.5)+
  geom_line(aes(y=low), color="#E69F00", size=0.5)+
  geom_line(aes(y=up), color="#E69F00", size=0.5)+
  scale_color_manual(values = cbp2)+
  labs(x = "g(.) sample", y = "Density Integration Estimate")+
  ylim(mxx+20*c(-esterr[N],esterr[N]))+
  theme_bw()
remove(xx, mxx, estint, esterr, dxx)
```


\subsection{item (c)}

Using just samples from the uniform distribution, use the acceptance-rejection method to estimate $\mathbb{E}(X)$ and $\mathbb{V}ar(X)$. To do this, do the following:
\begin{itemize}
    \item i. Generate a random variable X using the acceptance-rejection method. State how your algorithm works and that the acceptance test function is.
    \item ii. Give the rate of acceptance. That is, what percentage of proposed values is accepted.
    \item iii. Provide your estimates of $\mathbb{E}(X)$ and $\mathbb{V}ar(X)$ for this method.
\end{itemize}

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

\textbf{The Accept-Reject Method}

The \textit{pseudo-code} of Accept-Reject method applied to our problem can be summarized as follows:

\begin{algorithm}[H]
\SetAlgoLined
 Set $N=1,000$\;
 Set $acc=rej=0$\;
 Set $M=2$\;
 Set $y=zeros(N)$\; 
 \While{$acc \le N$}{
    \text{Propose X in support of $g(\cdot)$}\;
    \Begin{
        Set $x = runif(1, min=0, max=1)$\;
        Set $u = runif(1)$\;
        \eIf {$u\le g(x)/M$} {
          Increment $acc$\;
          Set $y[acc]=x$\;
        }{
          Increment $rej$\;
        }
    }
 }
 \caption{Accept Reject Method}
\end{algorithm}

The corresponding \texttt{R-Code} can be found in \textbf{Appendix}.  

Using this method, we have obtained the following results for the estimates to $\mathbb{E}(X)$ and $\mathbb{V}ar(X)$, including its \textit{acceptance rate}:

```{r}
# Initialize Variables
set.seed(923)

xrange <- 1 # Only values in range from 0 to 'xrange' are of interest
M <- 2      # Upper Limit

acc <- rej <- 0
y <- rep(0,N)   # vector of sampled data

while (acc <= N) {
  # Propose a 'x' on support of g
  x <- runif(1, min = 0, max = xrange)
  
  # Generate Accept/Rejection criteria for each fitted value
  u <- runif(1)
  
  # Maximum of value for distribution 'g'
  if (u <= g(x)/(M)) {
    acc <- acc + 1
    y[acc] <- x
  }
  else rej <- rej + 1
}

# Estimate E(X) and Var(X) using the sample of accepted values
EX_AcpRej <- mean(y)
VarX_AcpRej <- var(y)
SE_AcpRej <- sd(y)/sqrt(N)

# Print Statistics for Accept/Reject
cat("\n---- Summary Statistics for Accept-Reject Algorithm -----")
cat("\nE(X) : ",format(EX_AcpRej, digits = 2, nsmall = 4)) 
cat("\nS.E.: ",format(SE_AcpRej, digits = 5, nsmall = 4))
CR_AcpRej_up <- EX_AcpRej+2*SE_AcpRej; CR_AcpRej_lo <- EX_AcpRej-2*SE_AcpRej; 
cat("\n\n95% Credible Region for true-Mean (", 
    format(CR_AcpRej_lo, digits = 6, nsmall = 4), ",",
    format(CR_AcpRej_up, digits = 6, nsmall = 4),")\n")
cat("\nVar(X) : ",format(VarX_AcpRej, digits = 5, nsmall = 4)) 
cat("\n\nRate of Acceptance = ", format(acc/(acc+rej), digits = 2, nsmall = 4))
cat("\n---------------------------------------------------------------\n")

```

The histogram of the samples obtained by this method is as follows:

```{r, , fig.cap= "Histogram of simulated Accept/Reject", fig.width=4.5, fig.height=3.8}
dfy <- data.frame (YS = y)
ggplot(data=dfy, aes(x=YS))+
  geom_histogram(color="black", fill="white", bins=40)+
  scale_color_manual(values = cbp2)+
  labs(x = "g(.) sample", y = "Histogram of Y")+
  theme_bw()
remove(dfy)
```

\subsection{item (d)}

Use the Metropolis-Hasting algorithm to generate an MCMC sequence of $X_i$'s which have the triangle distribution as the invariant and the limiting distribution. Do this by doing the following:
\begin{itemize}
    \item Let the transition function, $q(x,y)$, be uniform density and have it not depend on the value of $x$. (That is, the new proposed move is always a sample from the uniform distribution on $[0,1]$ and this does not depend on the previous location. Therefore, $q(x,y) = 1$ for all values of $x$ and for $y\in[0,1]$.
    \item The invariant distribution is the triangle distribution. So, $u(x) = g(x)$.
    \item Don't burn in the chain and don't thin the chain.
    \begin{enumerate}[label=\roman*]
        \item What is the test function, $\alpha(x,y)$, for this chain given the above information?
        \item Provide the R code which samples the chain.
        \item What is the acceptance rate for the proposed moves in this chain?
        \item What are your estimates of $\mathbb{E}(X)$ and $\mathbb{V}ar(X)$?
    \end{enumerate}
\end{itemize}

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

Using the \textit{Metropolis-Hastings} method the \textit{test function} $\alpha(x,y)$ used was:

\begin{equation}
    \alpha(x,y)=\min\Bigg[\dfrac{g(x)}{g(y)},1\Bigg]\label{eq1d_01}
\end{equation}

... where $g(\cdot)$ is the \textit{density function of the triangular distribution} defined in \eqref{eq1_0}.

The R-Code for M-H algorithm is as follows:

```{r, echo=TRUE, eval=FALSE}
# Metropolis-Hastings Algorithm
alpha = function(x, y){ 
  min(1, g(x) / g(y))
}
x = rep(0, N)
acc <- 0

# Loop Sampling from the Chain
for(t in 2:N){
  ystar  <- runif(1, min=0, max=xrange)
  T <- runif(1)
  if( T <= alpha(ystar,x[t-1])) 
  {
    x[t] <- ystar
    acc <- acc+1
  } 
  else x[t] <- x[t-1]
}

```

... and we obtained the following results for the estimates to $\mathbb{E}(X)$ and $\mathbb{V}ar(X)$, including the \textit{acceptance rate}:

```{r}
#Setup Variables
set.seed(936)

alpha = function(x, y){ 
  min(1, g(x) / g(y))
}
x = rep(0, N)
acc <- 0

# Loop Sampling from the Chain
for(t in 2:N){
  ystar  <- runif(1, min=0, max=xrange)
  T <- runif(1)
  if( T <= alpha(ystar,x[t-1])) 
  {
    x[t] <- ystar
    acc <- acc+1
  } 
  else x[t] <- x[t-1]
}

# Print Rate of Acceptance
EX_MH <- mean(x)
Var_MH <- var(x)
SE_MH <- sd(x)/sqrt(N)

# Print Statistics for Metropolis-Hastings
cat("\n---- Summary Statistics for Metropolis-Hastings Algorithm -----")
cat("\nE(X) : ",format(EX_MH, digits = 2, nsmall = 4)) 
cat("\nS.E.: ",format(SE_MH, digits = 5, nsmall = 4))
CR_MH_up <- EX_MH+2*SE_MH; CR_MH_lo <- EX_MH-2*SE_MH; 
cat("\n\n95% Credible Region for true-Mean (", 
    format(CR_MH_lo, digits = 6, nsmall = 4), ",",
    format(CR_MH_up, digits = 6, nsmall = 4),")\n")
cat("\nVar(X) : ",format(Var_MH, digits = 5, nsmall = 4)) 
cat("\n\nRate of Acceptance = ", format(acc/N, digits = 2, nsmall = 4))
cat("\n---------------------------------------------------------------\n")



```

The histogram of the samples obtained by this method is as follows:

```{r, , fig.cap= "Histogram of simulated Metropolis-Hastings", fig.width=4.5, fig.height=3.8}
dfx <- data.frame (XS = x)
ggplot(data=dfx, aes(x=XS))+
  geom_histogram(color="black", fill="white", bins=40)+
  scale_color_manual(values = cbp2)+
  labs(x = "g(.) sample", y = "Histogram of X")+
  theme_bw()
remove(dfx)
```

\subsubsection{Comparison between each method's estimate for $\mathbb{E}(X)$}

We plotted each $95\%$ Credible Region obtained on each method and the results are as follows:

```{r, fig.cap= "Comparative C.R. for E(X) between each method", fig.width=4.5, fig.height=3.8}
# Prepare Data - Get delta[1-12]
# D3_Work <- as.data.frame(DiabetDrug_M1[["summary"]][4:15,c(1:3,5,7)])

# Generates Studies labels
StudyLst <- rapply(list(c("Z-Estimate", "Imp.Samp.","Accept/Reject","Metr.Hast.")), 
                   sprintf, fmt = "%10s", how = "replace")

# Collects C.R's from Summary report 
CR_Estim <- data.frame(ID = StudyLst[[1]], 
                       lower = c(CR_Z_lo, CR_IS_lo, CR_AcpRej_lo, CR_MH_lo), 
                       estim = c(EZ, EX_IS, EX_AcpRej, EX_MH), 
                       upper = c(CR_Z_up, CR_IS_up, CR_AcpRej_up, CR_MH_up))

# Organize data to generate graphs & analysis
P1 <- CR_Estim %>% 
  ggplot() +
  geom_point(aes(x=ID, y=estim, color=ID), size=2.5) +
  geom_errorbar(aes(x=ID, ymin=lower, ymax=upper, color=ID), width = 1) +
  xlab("Algorithm") +
  ylab(expression("Estimate / C.R.")) +
  scale_color_manual(values = cbp2)+
  theme_bw()

P1 + theme(axis.text.x=element_blank())
```

\underline{Comment}:- Comparing the four methods we can see that \textit{Accept/Reject} and \textit{Metropolis-Hastings} have provided very similar estimates and respective Credible Regions for $\mathbb{E}(X)$. The estimate that most approximate the \textit{true-mean} was \textit{Z-Estimate}\footnote{Composed by $Z=\frac{U_1+U_2}{2}$, where $U_1$ and $U_2$ are \textit{Uniform$[0,1]$}}. On the other hand, \textit{Importance Sampling} generated the poorest estimate of all methods for $\mathbb{E}(X)$ and the most elastic Credible Region, as well.

\pagebreak

\section{Question 2}

In this problem we will analysis an experiment which studies the effect of a dose of a drug on the growth of rats. The data is in the file \texttt{BigRatDat.txt} and is described below. This data consists of the growth of 50 rats, where 10 rats were randomly assigned to five different doses of a drug. (The dose levels are 0, .5, 1, 4, and 8 units of the drug.) The weights of the rats were obtained each week for 11 weeks. The data file is sent along with the file for this homework. The data file has the following structure:

\begin{verbatim}
Column 1: Doses levels
Column 2: Rat number (note: the rats are different for the different dose levels.
Column 3: Week 1 weight
Column 4: Week 2 weight
Column 5: Week 3 weight
Column 6: Week 4 weight
Column 7: Week 5 weight
Column 8: Week 6 weight
Column 9: Week 7 weight
Column 10: Week 8 weight
Column 11: Week 9 weight
Column 12: Week 10 weight
Column 13: Week 11 weight
\end{verbatim}

The first several lines of the file \texttt{BigRatDat.txt} are below:

\begin{verbatim}
0 1 54 60 63 74 77 89 93 100 108 114 124
0 2 69 75 81 90 97 120 114 119 126 138 143
0 3 77 81 87 94 101 110 117 124 134 141 151
0 4 64 69 77 83 88 96 104 109 120 123 131
0 5 51 58 62 71 74 81 88 93 99 103 113
0 6 64 71 77 89 90 100 106 114 122 134 139
0 7 80 91 97 101 111 119 129 131 137 147 154
0 8 79 85 89 99 104 105 116 121 132 139 147
0 9 77 82 88 92 101 109 119 127 135 144 158
0 10 79 84 91 98 107 114 119 131 137 146 155
.5 1 62 71 75 79 87 91 100 105 111 121 124
.5 2 68 73 81 89 94 101 110 114 123 132 139
.5 3 94 102 109 110 128 133 147 151 153 171 184
.5 4 81 90 95 102 109 120 128 137 141 154 160
\end{verbatim}

Do the following:

\subsection{item (a)}

Model this data with a growth curve model. So, for the $i$th rat, you should fit a regression line with the basic form: $Y_{ij} = \beta_{0i} + \beta_{1i} \times week_j + \epsilon_{ij}$ . For the $\beta$'s, you should model them as a linear relationship with the dose level. For example, you should model $\beta_{0i}$ as a normal distribution with some precision and with $\mathbb{E}[\beta_{0i}] = \beta_{00} +\beta_{01}\times \text{DoseLevel}_i$. The coefficient $\beta_{1i}$ is
modelled similarly. (That is, the $\beta_{0i}$ and $\beta_{1i}$ each follow a normal distribution with some mean and precision.) Pick priors which are not restrictive. Show the WinBugs/OpenBUGS/JAGS code used to model this data. (If you run this through R, then please provide this code also.) 

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

```{r}
# Setup Data-set - Read Data
RatGrowth=read.table("Data/RatData11weeks.csv", header=TRUE, sep = ",")

# Setup Variables (ORIGINAL DATABASE)
N <- nrow(RatGrowth)  # Number of Items in data-set
ni <- length(unique(RatGrowth$IDinDose))  # No. of Rats on each dose level
nj <- ncol(RatGrowth)-2      # No. of Weeks of treatment
nk <- length(unique(RatGrowth$dose))      # No. of dose levels

ProdRun <- TRUE  # Control Variable for Testing/Production run

if (ProdRun) {
  # Production Setup OpenBugs running parameters
  NSim <- 30000    # No. of simulations for production
  NChain <- 3      # No. of chains for production
  NThin <- 8      # n.thin parameter for production
  Burnin <- 10000  # Burn-In parameter for production
  Sz <- 5000       # Size of samples for trace/acf plots
} else {
  # Testing Setup OpenBugs running parameters
  NSim <- 5000    # No. of simulations for production
  NChain <- 3      # No. of chains for production
  NThin <- 5      # n.thin parameter for production
  Burnin <- 1000  # Burn-In parameter for production
  Sz <- 1000       # Size of samples for trace/acf plots
  
}

```


```{r}
# Printing the Data-Frame
RatGrowth %>%
  kbl(booktabs = TRUE, digits = 4, longtable = TRUE,
      caption = "Data - Growth in Rats under Treatment") %>% 
  kable_styling(latex_options = "striped")
 
```


```{r}
# Model 0 - Standard Model

# Setup variables
y <- as.matrix(RatGrowth[,c(paste0("week",c(1:nj)))])
doselevel <- RatGrowth[,"dose"]
doselevel.c <- RatGrowth[,"dose"]-mean(RatGrowth[,"dose"])
week <- c(1:nj)
week.c <- c(1:nj)-mean(c(1:nj))

# Setup Model in OpenBugs
cat("
model{
  for (i in 1:N) {
    for (j in 1:nj) {
      y[i,j] ~dnorm(mu[i,j], tau.w)
      mu[i,j] <- beta0[i]+beta1[i]*week[j]
    }
    beta0[i]~dnorm(mu0[i], tau.b0)
    beta1[i]~dnorm(mu1[i], tau.b1)
    mu0[i] <- beta00+beta01*doselevel[i]
    mu1[i] <- beta10+beta11*doselevel[i]
  }
  beta00 ~ dnorm(100.0, 0.00001)
  beta01 ~ dnorm(0.0, 0.0001)
  beta10 ~ dnorm(0.0, 0.0001)
  beta11 ~ dnorm(0.0, 0.0001)
  
  s.y ~dunif(0.0, 250.0)
  s.b0 ~dunif(0.0, 250.0)
  s.b1 ~dunif(0.0, 250.0)

  tau.w <- pow(s.y, -2)
  tau.b0 <- pow(s.b0, -2)
  tau.b1 <- pow(s.b1, -2)
}", file="RatsGrowthM0.txt")
  
# Setup Parameters
paramsM0=c("tau.w", "beta0", "beta1",
           "beta00", "beta01", "beta10", "beta11", 
           "tau.b0", "tau.b1")

bugM0.dat=list("y", "week", "doselevel", "N", "nj")  # what variable you need in the model

```


```{r}
# Setup Initial Values- Stochastic Components
set.seed(963)
initM0.fun=function(){ list(  
  beta0 = rnorm(N,50.0,10.0), 
  beta1 = rnorm(N,50.0,10.0),
  beta00 = rnorm(1,100.0, 0.00001),
  beta01 = rnorm(1,0.0, 0.0001),
  beta10 = rnorm(1,0.0, 0.0001),
  beta11 = rnorm(1,0.0, 0.0001),
  s.y = runif(1, 0.0, 250.0),  
  s.b0 = runif(1, 0.0, 250.0), 
  s.b1 = runif(1, 0.0, 250.0) 
  ) }
```


```{r, cache=TRUE}
# Run Open Bugs - Parameters according with 'ProdRun' flag
set.seed(2602)
attach(RatGrowth)
RatGrowthM0=bugs(bugM0.dat, initM0.fun, paramsM0, model.file="RatsGrowthM0.txt",
                 n.chains=NChain, n.iter=NSim, n.burnin=Burnin, n.thin=NThin, debug=FALSE)
detach(RatGrowth)

# Get Simulation from OpenBugs
SArrayM0 <-  RatGrowthM0$sims.array   # Data Arrays
vname <- attr(SArrayM0,"dimnames")[3][[1]]  # Variable Names

# Get Summary statistics of parameters of Interest
RNames <- rownames(RatGrowthM0[["summary"]]) # List of parameters
df_SummaryM0 <- data.frame(Parameter = RNames)
df_SummaryM0 <- cbind(df_SummaryM0, as_tibble(RatGrowthM0[["summary"]]))
rownames(df_SummaryM0) <- RNames

```

The model\footnote{Another possible approach for this question would be to consider the centered mean of the covariate $W$ (which represents \texttt{week}), considering the recomendation of \cite{Cowles} which says when all of the possible values of the covariate are of the same sign and away from zero, the mathematical definition of the intercept may not make sense substantively.}\footnote{The counterparty of this approach is to deal with a different covariance matrix structure where identifying how the variance is growing at the dose level, for instance, could be troublesome. However, this would bring additional complexities on interpretability of the model which is beyond the scope of this question.} created to this question is as follows:

\underline{Openbugs Model}

\begin{verbatim}
model{
  for (i in 1:N) {
    for (j in 1:nj) {
      y[i,j] ~dnorm(mu[i,j], tau.w)
      mu[i,j] <- beta0[i]+beta1[i]*week[j]
    }
    beta0[i]~dnorm(mu0[i], tau.b0)
    beta1[i]~dnorm(mu1[i], tau.b1)
    mu0[i] <- beta00+beta01*doselevel[i]
    mu1[i] <- beta10+beta11*doselevel[i]
  }
  beta00 ~ dnorm(100.0, 0.00001)
  beta01 ~ dnorm(0.0, 0.0001)
  beta10 ~ dnorm(0.0, 0.0001)
  beta11 ~ dnorm(0.0, 0.0001)
  
  s.y ~dunif(0.0, 250.0)
  s.b0 ~dunif(0.0, 250.0)
  s.b1 ~dunif(0.0, 250.0)

  tau.w <- pow(s.y, -2)
  tau.b0 <- pow(s.b0, -2)
  tau.b1 <- pow(s.b1, -2)
}
\end{verbatim}

\subsection{item (b)}

Provide some preliminary evidence that the model looks like it converged. You do not have to do the more advanced statistics (for the purpose of this assignment). It is sufficient to show trace plots and some auto correlation values. (Don't do this for each individual rat's $\beta$ parameters, it is sufficient to show these values for the parameters of the hierarchical parameters.)

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

In order to verify the convergence and auto-correlation of our estimates we will plot a sample trace-plots\footnote{In order to avoid too many points on each graph, affecting the display performance of PDF file, we limited the number of points to $5,000$ which is a good representation of parameter's convergence.} and ACF-plots\footnote{For ACF-Plots we will use the chain-1 to verify for potential auto-correlations of parameter estimates.} and the results are as follows:

```{r, fig.cap= "Trace-plots of $\\beta_{00}$, $\\beta_{01}$, $\\beta_{10}$ and $\\beta_{11}$ (Run-0)", fig.height=3.5, fig.width=4.5}
# Plot TracePlots * BETA00, BETA01, BETA10, BETA11*

# Sampling 5000 points to generate "thinner" traceplots
set.seed(312)

L <- NSim-Burnin

S <- if (Sz < L) sort(sample(1:L, Sz, replace = FALSE)) else 1:Sz
 
# Build working dataframe
D_WorkBeta00 <- data.frame(ValCh1=SArrayM0[S,1,paste0("beta00")],
                           ValCh2=SArrayM0[S,2,paste0("beta00")],
                           ValCh3=SArrayM0[S,3,paste0("beta00")])

D_WorkBeta01 <- data.frame(ValCh1=SArrayM0[S,1,paste0("beta01")],
                           ValCh2=SArrayM0[S,2,paste0("beta01")],
                           ValCh3=SArrayM0[S,3,paste0("beta01")])

D_WorkBeta10 <- data.frame(ValCh1=SArrayM0[S,1,paste0("beta10")],
                           ValCh2=SArrayM0[S,2,paste0("beta10")],
                           ValCh3=SArrayM0[S,3,paste0("beta10")])

D_WorkBeta11 <- data.frame(ValCh1=SArrayM0[S,1,paste0("beta11")],
                           ValCh2=SArrayM0[S,2,paste0("beta11")],
                           ValCh3=SArrayM0[S,3,paste0("beta11")])

# Plot Traceplots for selected data-frames
P1 <- D_WorkBeta00 %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta['00'])) +
        theme_bw()
P2 <- D_WorkBeta01 %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta['01'])) +
        theme_bw()
P3 <- D_WorkBeta10 %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta['10'])) +
        theme_bw()
P4 <- D_WorkBeta11 %>%
        ggplot(aes(seq(from=1,to=Sz)))+
        geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
        geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
        geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
        labs(y = expression(beta['11'])) +
        theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"), 
                  P2+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"),
                  P3+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"),
                  P4+theme(axis.text.x=element_blank(),
                               axis.title.x=element_blank(),
                               legend.position="none"), ncol = 2, nrow = 2)

# Remove Working Variable to free memory
remove(D_WorkBeta00, D_WorkBeta01, D_WorkBeta10, D_WorkBeta11 )
```


```{r, fig.cap= "ACF-plots of $\\beta_{00}$, $\\beta_{01}$, $\\beta_{10}$ and $\\beta_{11}$ (max-Lag=100) (Run-0)"}
# Plot ACF Plots * BETA00, BETA01, BETA10, BETA11*

# Build working dataframe
D_WorkBeta00 <- data.frame(ValCh1=SArrayM0[,1,paste0("beta00")])
D_WorkBeta01 <- data.frame(ValCh1=SArrayM0[,1,paste0("beta01")])
D_WorkBeta10 <- data.frame(ValCh1=SArrayM0[,1,paste0("beta10")])
D_WorkBeta11 <- data.frame(ValCh1=SArrayM0[,1,paste0("beta11")])

# Plot ACF Plots for selected data-frames
P1 <- ggAcf(D_WorkBeta00$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta['00'])) +
  ggtitle(NULL)+
  theme_bw()
P2 <- ggAcf(D_WorkBeta01$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta['01'])) +
  ggtitle(NULL)+
  theme_bw()
P3 <- ggAcf(D_WorkBeta10$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta['10'])) +
  ggtitle(NULL)+
  theme_bw()
P4 <- ggAcf(D_WorkBeta11$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta['11'])) +
  ggtitle(NULL)+
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)
# Remove Working Variable to free memory
remove(D_WorkBeta00, D_WorkBeta01, D_WorkBeta10, D_WorkBeta11 )
```

\underline{Comment}:- We can see from trace and ACF plots that we have \underline{no evidence} that our estimates of hierarchical parameters have not converged or are auto-correlated.


\subsection{item (c)}

Provide the posterior distribution for the parameters of the distribution of the $\beta$'s That is, the $\beta_{0i}$'s, $\beta_{1i}$'s and the $\beta_{00}$, $\beta_{01}$, $\beta_{10}$, and $\beta_{11}$ parameters. (For this subquestion, you don't need to supply the density estimation. You may just provide the usual summary statistics for the distributions.) (This is for the mean and precision parameters which are discussed in part (a) of this question. ) Also, provide the posterior distribution for the precision of $\epsilon_{ij}$ (which is defined in (a) above.)

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

The posterior distribution of parameters $\beta_{0i}$'s, $\beta_{1i}$'s and the $\beta_{00}$, $\beta_{01}$, $\beta_{10}$, and $\beta_{11}$ are as follows:

```{r}
# Print statistics of interest - Beta0i and Beta1i
df_Prt <- df_SummaryM0[c(paste0("beta0[",c(1:N),"]"),
                         paste0("beta1[",c(1:N),"]")),c(2:4,6,8)]

df_Prt %>%
  kbl(booktabs = TRUE, digits = 4, longtable = TRUE, 
      caption = "Summary - Beta0i and Beta1i for Rat Growth (Run-0)") %>% 
  kable_styling(latex_options = "striped")
```

```{r}
# Print statistics of interest - beta00-beta11
df_Prt <- df_SummaryM0[c("beta00", "beta01", "beta10", "beta11"),c(2:4,6,8)]

df_Prt %>%
  kbl(booktabs = TRUE, digits = 4,
      caption = "Summary - beta00-beta11 for Rat Growth (Run-0)") %>% 
  kable_styling(latex_options = "striped")
```

```{r}
# Print statistics of interest - Precisions
df_Prt <- df_SummaryM0[c("tau.w", "tau.b0", "tau.b1"),c(2:4,6,8)]

df_Prt %>%
  kbl(booktabs = TRUE, digits = 4,
      caption = "Summary - Precisions for Rat Growth (Run-0)") %>% 
  kable_styling(latex_options = "striped")
```

\subsection{item (d)}

Is there any effect due to the drug dose level. Please provide your posterior belief that there is a difference. In justifying your answer, you should include the appropriate posterior distribution.

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

In order to investigate the effect of each drug levels on rat's weight we first plotted the boxplot, grouped by drug level, per week. 

```{r, fig.cap= "Comparative Weights by dose, by week", fig.width=7.5, fig.height=5.0}
# Create Temporary data-frame
D1_Work <- RatGrowth
colnames(D1_Work) <- c("dose", "IDinDose", "week01","week02","week03","week04","week05",
                         "week06","week07","week08","week09","week10","week11")

P2 <- D1_Work %>% 
  pivot_longer(cols = week01:week11, names_to = "weekStr", values_to = "rweight") %>%
  mutate(weekNo = as.integer(substr(weekStr,5,length(weekStr)-5))) %>% 
  ggplot(aes(group=weekNo))+ 
  geom_boxplot(aes(x=weekStr, y=rweight)) +
  labs(y="Weight (in g)")+
  facet_grid(~dose)+
  theme_bw()
P2 + theme(axis.title.x=element_blank(),
           axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8))
remove(D1_Work)

```

\underline{Comment}:- Comparing the boxplots for each dose level and respective evolution of weight per week we noticed a slight decrease on weight levels at each grid of dose level. We will now verify if its plausible to assume there is a consistent difference between them.

\medskip

The parameters associated with the effect of drug level are $\beta_{00}$, $\beta_{01}$, $\beta_{10}$ and $\beta_{11}$ and their respective posterior estimates are represented below.

```{r, fig.cap="Posterior Distributions $\\beta_{00}$, $\\beta_{01}$, $\\beta_{10}$ and $\\beta_{11}$"}
# Prepare Data-Frame for next steps
D1_Work <- rbind(data.frame(beta00=SArrayM0[,1,paste0("beta00")],
                            beta01=SArrayM0[,1,paste0("beta01")],
                            beta10=SArrayM0[,1,paste0("beta10")],
                            beta11=SArrayM0[,1,paste0("beta11")], Chain=factor(1)),
                 data.frame(beta00=SArrayM0[,2,paste0("beta00")],
                            beta01=SArrayM0[,2,paste0("beta01")],
                            beta10=SArrayM0[,2,paste0("beta10")],
                            beta11=SArrayM0[,2,paste0("beta11")], Chain=factor(2)),
                 data.frame(beta00=SArrayM0[,3,paste0("beta00")],
                            beta01=SArrayM0[,3,paste0("beta01")],
                            beta10=SArrayM0[,3,paste0("beta10")],
                            beta11=SArrayM0[,3,paste0("beta11")], Chain=factor(3)))

# Plot the Graphs of beta00, beta01, beta10, beta11
P1 <- D1_Work %>%
  ggplot(mapping = aes(x = beta00, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(beta['00']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

P2 <- D1_Work %>%
  ggplot(mapping = aes(x = beta01, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(beta['01']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

P3 <- D1_Work %>%
  ggplot(mapping = aes(x = beta10, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(beta['10']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

# Plot the Graphs of Tau
P4 <-D1_Work %>%
  ggplot(mapping = aes(x = beta11, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(beta['11']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

ggpubr::ggarrange(P1, P2, P3, P4, ncol = 2, nrow = 2)

# Remove Working Variable to free memory
remove(D1_Work)
```


```{r, fig.cap="Posterior Distributions $\\tau_w$, $\\tau_{\\beta_0}$ and $\\tau_{\\beta_1}$"}
# Prepare Data-Frame for next steps
D2_Work <- rbind(data.frame(tau.w=SArrayM0[,1,paste0("tau.w")],
                            tau.b0=SArrayM0[,1,paste0("tau.b0")],
                            tau.b1=SArrayM0[,1,paste0("tau.b1")], Chain=factor(1)),
                 data.frame(tau.w=SArrayM0[,2,paste0("tau.w")],
                            tau.b0=SArrayM0[,2,paste0("tau.b0")],
                            tau.b1=SArrayM0[,2,paste0("tau.b1")], Chain=factor(2)),
                 data.frame(tau.w=SArrayM0[,3,paste0("tau.w")],
                            tau.b0=SArrayM0[,3,paste0("tau.b0")],
                            tau.b1=SArrayM0[,3,paste0("tau.b1")], Chain=factor(3)))


# Plot the Graphs of TAU_W, TAU_Beta0, TAU_Beta1
P1 <- D2_Work %>%
  ggplot(mapping = aes(x = tau.w, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(tau['w']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

P2 <- D2_Work %>%
  ggplot(mapping = aes(x = tau.b0, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(tau['b0']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

# Plot the Graphs of Tau
P3 <-D2_Work %>%
  ggplot(mapping = aes(x = tau.b1, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(tau['b1']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

ggpubr::ggarrange(P1, P2, P3, ncol = 1, nrow = 3)

# Remove Working Variable to free memory
remove(D2_Work)
```


\textbf{Comments}:- Using the \textbf{modeling results} and \textbf{posterior estimates of the parameters} we have obtained the following coefficients $\beta_{01}=-0.4698$ and $\beta_{11}=-0.1487$ which represents the expected effect of the dose level over the intercept and slope, respectively, of the predictive populational weight. As both posterior estimates of these parameters are \textit{negative} this might indicate that \textit{the increase of the number of units of the drug have a \underline{negative effect} over rat's weight over the weeks}.

In other words, we can say that, for each increase in dose level, the expected \textit{weekly growth rate} ($\beta_{1i}$) of the rat \textit{decreases} $14.87\%$. Similar conclusion can be drawn for the intercept ruled by $\beta_{0i}$, i.e., the expected starting value for rat's weight is negatively affected and each increase of dose-level makes the \textit{expected startig weight} decrease $46.98\%$ in average.

\subsection{item (e)}

In a short paragraph, summarize your belief in the effect of the drug dose level. In this summary, you should state what the strength of the evidence from the posterior distributions.

\medskip

{\setlength{\parindent}{0cm}\textit{Solution.}}

\textbf{Comments}:- From the posterior $95\%$ Credible Region for these parameters, we have that $\beta_{01}\in[-1.3370,0.4101]$ and $\beta_{11}\in[-0.2352,-0.0629]$. This suggests that, depending on the drug level, the effect of $\beta_{11}$ is negative with $95\%$ of certainty which negatively affects the slope of the populational weight, as the drug level increases. This makes us to believe that there is evidences from the posterior distribution of parameter $\beta_{11}$ that \textit{the drug indeed has an effect on rat's weight and this effect is \underline{negative}, i.e., it is expected that their weights will decrease as the number of units of the drug increases}.

\pagebreak

\begin{thebibliography}{5}

\bibitem{Casella} 
Robert, C. P., Casella, G., 
\textit{Introducing Monte Carlo Methods with R}. Chap.6, pp.167 - Springer, 2010.

\bibitem{GelmanHill} 
Gelman, A., Hill, J.
\textit{Data Analysis using Regression and Multilevel/Hierarchical Models}, Cambridge Press, 2007.

\bibitem{MarinRobert} 
Marin, J. M., Robert, C.
\textit{Bayesian Essentials with R}, 2nd. Ed. pp.49 - Springer, 2014.

\bibitem{Congdon}
Congdon, P.
\textit{Applied Bayesian Modelling}, 2nd. Edition, Wiley, 2014

\bibitem{Cowles}
Cowles, M.K.
\textit{Applied Bayesian Statistics with R and OpenBugs}, Springer, 2013

\end{thebibliography}

\pagebreak

\section{Appendix - R-Code}


```{r, echo=TRUE, eval=FALSE}
library(tidyverse)
library(R2OpenBUGS)
library(kableExtra)
library(coda)


library(ggplot2)
library(forecast)

# The palette with black - Used in Graphs with :
cbp1 <- c("#999999", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbp2 <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbp3 <- c("#FFDB6D", "#C4961A", "#F4EDCA", "#D16103", 
          "#C3D7A4", "#52854C", "#4E84C4", "#293352")

# Triangular Distribution
g=function(x){
  (x>0)*(x<1)*((x<=0.5)*4*x+ (x>0.5)*(4-4*x))
}

# Set parameters
N = 1000

set.seed(123)

# Generating two independent samples U1 and U2 from Uniform[0,1]
U1 <- runif(N)
U2 <- runif(N)

# Calculating the exact distribution of Z:= (U1+U2)/2
Z <- (U1+U2)/2

# Estimate E(X) and E(Y) Considerin that Z ~Triang(g)
EZ <- mean(Z)
VarZ <- var(Z)
SE_Z <- sd(Z)/sqrt(N)

# Print Statistics for Approx. Z
cat("\n---- Summary Statistics for approx. Z=(U1+U2)/2 ---------------")
cat("\nE(X) : ",format(EZ, digits = 2, nsmall = 4)) 
cat("\nS.E.: ",format(SE_Z, digits = 5, nsmall = 4))
CR_Z_up <- EZ+2*SE_Z; CR_Z_lo <- EZ-2*SE_Z; 
cat("\n\n95% Credible Region for true-Mean (", 
    format(CR_Z_lo, digits = 6, nsmall = 4), ",",
    format(CR_Z_up, digits = 6, nsmall = 4),")\n")
cat("\nVar(X) : ",format(VarZ, digits = 5, nsmall = 4)) 
cat("\n---------------------------------------------------------------\n")


dfz <- data.frame (ZS = Z)
ggplot(data=dfz, aes(x=ZS))+
  geom_histogram(color="black", fill="white", bins=40)+
  scale_color_manual(values = cbp2)+
  labs(x = "g(.) sample", y = "Histogram of Z")+
  theme_bw()
remove(dfz)

# Item (b) - here h_1(X) = X => h_1(U3)=U3
set.seed(725)
U3 <- runif(N)

# Estimate E(X) via Importance Sampling 
EX_IS <- (1/N)*sum((U3*g(U3))/(1))

# here h_2(X) = X^2 => h_1(U3)=U3^2
EX_IS2 <- (1/N)*sum((U3^2*g(U3))/(1))
VarX_IS <- EX_IS2-EX_IS^2
SE_IS <- sd((U3*g(U3))/(1))/sqrt(N)

# Print Statistics for Importance Sampling
cat("\n---- Summary Statistics for Importance Sampling Algorithm -----")
cat("\nE(X) : ",format(EX_IS, digits = 2, nsmall = 4)) 
cat("\nS.E.: ",format(SE_IS, digits = 5, nsmall = 4))
CR_IS_up <- EX_IS+2*SE_IS; CR_IS_lo <- EX_IS-2*SE_IS; 
cat("\n\n95% Credible Region for true-Mean (", 
    format(CR_IS_lo, digits = 6, nsmall = 4), ",",
    format(CR_IS_up, digits = 6, nsmall = 4),")\n")
cat("\nVar(X) : ",format(VarX_IS, digits = 5, nsmall = 4)) 
cat("\n---------------------------------------------------------------\n")


# Adapted from Robert, Casella - pp.66
xx=g(U3)
mxx <- mean(xx)
estint=cumsum(xx)/(1:N)
esterr=sqrt(cumsum((xx-estint)^2))/(1:N)
dxx <- data.frame(yest = estint,
                  low = estint-2*esterr,
                  up = estint+2*esterr)
ggplot(data=dxx, aes(x=c(1:N)))+
  geom_line(aes(y=yest), size=0.5)+
  geom_line(aes(y=low), color="#E69F00", size=0.5)+
  geom_line(aes(y=up), color="#E69F00", size=0.5)+
  scale_color_manual(values = cbp2)+
  labs(x = "g(.) sample", y = "Density Integration Estimate")+
  ylim(mxx+20*c(-esterr[N],esterr[N]))+
  theme_bw()
remove(xx, mxx, estint, esterr, dxx)

# Initialize Variables
set.seed(923)

xrange <- 1 # Only values in range from 0 to 'xrange' are of interest
M <- 2      # Upper Limit

acc <- rej <- 0
y <- rep(0,N)   # vector of sampled data

while (acc <= N) {
  # Propose a 'x' on support of g
  x <- runif(1, min = 0, max = xrange)
  
  # Generate Accept/Rejection criteria for each fitted value
  u <- runif(1)
  
  # Maximum of value for distribution 'g'
  if (u <= g(x)/(M)) {
    acc <- acc + 1
    y[acc] <- x
  }
  else rej <- rej + 1
}

# Estimate E(X) and Var(X) using the sample of accepted values
EX_AcpRej <- mean(y)
VarX_AcpRej <- var(y)
SE_AcpRej <- sd(y)/sqrt(N)

# Print Statistics for Accept/Reject
cat("\n---- Summary Statistics for Accept-Reject Algorithm -----")
cat("\nE(X) : ",format(EX_AcpRej, digits = 2, nsmall = 4)) 
cat("\nS.E.: ",format(SE_AcpRej, digits = 5, nsmall = 4))
CR_AcpRej_up <- EX_AcpRej+2*SE_AcpRej; CR_AcpRej_lo <- EX_AcpRej-2*SE_AcpRej; 
cat("\n\n95% Credible Region for true-Mean (", 
    format(CR_AcpRej_lo, digits = 6, nsmall = 4), ",",
    format(CR_AcpRej_up, digits = 6, nsmall = 4),")\n")
cat("\nVar(X) : ",format(VarX_AcpRej, digits = 5, nsmall = 4)) 
cat("\n\nRate of Acceptance = ", format(acc/(acc+rej), digits = 2, nsmall = 4))
cat("\n---------------------------------------------------------------\n")


dfy <- data.frame (YS = y)
ggplot(data=dfy, aes(x=YS))+
  geom_histogram(color="black", fill="white", bins=40)+
  scale_color_manual(values = cbp2)+
  labs(x = "g(.) sample", y = "Histogram of Y")+
  theme_bw()
remove(dfy)

#Setup Variables
set.seed(936)

alpha = function(x, y){ 
  min(1, g(x) / g(y))
}
x = rep(0, N)
acc <- 0

# Loop Sampling from the Chain
for(t in 2:N){
  ystar  <- runif(1, min=0, max=xrange)
  T <- runif(1)
  if( T <= alpha(ystar,x[t-1])) 
  {
    x[t] <- ystar
    acc <- acc+1
  } 
  else x[t] <- x[t-1]
}

# Print Rate of Acceptance
EX_MH <- mean(x)
Var_MH <- var(x)
SE_MH <- sd(x)/sqrt(N)

# Print Statistics for Metropolis-Hastings
cat("\n---- Summary Statistics for Metropolis-Hastings Algorithm -----")
cat("\nE(X) : ",format(EX_MH, digits = 2, nsmall = 4)) 
cat("\nS.E.: ",format(SE_MH, digits = 5, nsmall = 4))
CR_MH_up <- EX_MH+2*SE_MH; CR_MH_lo <- EX_MH-2*SE_MH; 
cat("\n\n95% Credible Region for true-Mean (", 
    format(CR_MH_lo, digits = 6, nsmall = 4), ",",
    format(CR_MH_up, digits = 6, nsmall = 4),")\n")
cat("\nVar(X) : ",format(Var_MH, digits = 5, nsmall = 4)) 
cat("\n\nRate of Acceptance = ", format(acc/N, digits = 2, nsmall = 4))
cat("\n---------------------------------------------------------------\n")


dfx <- data.frame (XS = x)
ggplot(data=dfx, aes(x=XS))+
  geom_histogram(color="black", fill="white", bins=40)+
  scale_color_manual(values = cbp2)+
  labs(x = "g(.) sample", y = "Histogram of X")+
  theme_bw()
remove(dfx)

# Prepare Data - Get delta[1-12]
# D3_Work <- as.data.frame(DiabetDrug_M1[["summary"]][4:15,c(1:3,5,7)])

# Generates Studies labels
StudyLst <- rapply(list(c("Z-Estimate", "Imp.Samp.","Accept/Reject","Metr.Hast.")), 
                   sprintf, fmt = "%10s", how = "replace")

# Collects C.R's from Summary report 
CR_Estim <- data.frame(ID = StudyLst[[1]], 
                       lower = c(CR_Z_lo, CR_IS_lo, CR_AcpRej_lo, CR_MH_lo), 
                       estim = c(EZ, EX_IS, EX_AcpRej, EX_MH), 
                       upper = c(CR_Z_up, CR_IS_up, CR_AcpRej_up, CR_MH_up))

# Organize data to generate graphs & analysis
P1 <- CR_Estim %>% 
  ggplot() +
  geom_point(aes(x=ID, y=estim, color=ID), size=2.5) +
  geom_errorbar(aes(x=ID, ymin=lower, ymax=upper, color=ID), width = 1) +
  xlab("Algorithm") +
  ylab(expression("Estimate / C.R.")) +
  scale_color_manual(values = cbp2)+
  theme_bw()

P1 + theme(axis.text.x=element_blank())

# Setup Data-set - Read Data
RatGrowth=read.table("Data/RatData11weeks.csv", header=TRUE, sep = ",")

# Setup Variables (ORIGINAL DATABASE)
N <- nrow(RatGrowth)  # Number of Items in data-set
ni <- length(unique(RatGrowth$IDinDose))  # No. of Rats on each dose level
nj <- ncol(RatGrowth)-2      # No. of Weeks of treatment
nk <- length(unique(RatGrowth$dose))      # No. of dose levels

ProdRun <- TRUE  # Control Variable for Testing/Production run

if (ProdRun) {
  # Production Setup OpenBugs running parameters
  NSim <- 30000    # No. of simulations for production
  NChain <- 3      # No. of chains for production
  NThin <- 8      # n.thin parameter for production
  Burnin <- 10000  # Burn-In parameter for production
  Sz <- 5000       # Size of samples for trace/acf plots
} else {
  # Testing Setup OpenBugs running parameters
  NSim <- 5000    # No. of simulations for production
  NChain <- 3      # No. of chains for production
  NThin <- 5      # n.thin parameter for production
  Burnin <- 1000  # Burn-In parameter for production
  Sz <- 1000       # Size of samples for trace/acf plots
  
}


# Printing the Data-Frame
RatGrowth %>%
  kbl(booktabs = TRUE, digits = 4, longtable = TRUE,
      caption = "Data - Growth in Rats under Treatment") %>% 
  kable_styling(latex_options = "striped")
 

# Model 0 - Standard Model

# Setup variables
y <- as.matrix(RatGrowth[,c(paste0("week",c(1:nj)))])
doselevel <- RatGrowth[,"dose"]
doselevel.c <- RatGrowth[,"dose"]-mean(RatGrowth[,"dose"])
week <- c(1:nj)
week.c <- c(1:nj)-mean(c(1:nj))

# Setup Model in OpenBugs
cat("
model{
  for (i in 1:N) {
    for (j in 1:nj) {
      y[i,j] ~dnorm(mu[i,j], tau.w)
      mu[i,j] <- beta0[i]+beta1[i]*week[j]
    }
    beta0[i]~dnorm(mu0[i], tau.b0)
    beta1[i]~dnorm(mu1[i], tau.b1)
    mu0[i] <- beta00+beta01*doselevel[i]
    mu1[i] <- beta10+beta11*doselevel[i]
  }
  beta00 ~ dnorm(100.0, 0.00001)
  beta01 ~ dnorm(0.0, 0.0001)
  beta10 ~ dnorm(0.0, 0.0001)
  beta11 ~ dnorm(0.0, 0.0001)
  
  s.y ~dunif(0.0, 250.0)
  s.b0 ~dunif(0.0, 250.0)
  s.b1 ~dunif(0.0, 250.0)

  tau.w <- pow(s.y, -2)
  tau.b0 <- pow(s.b0, -2)
  tau.b1 <- pow(s.b1, -2)
}", file="RatsGrowthM0.txt")
  
# Setup Parameters
paramsM0=c("tau.w", "beta0", "beta1",
           "beta00", "beta01", "beta10", "beta11", 
           "tau.b0", "tau.b1")

bugM0.dat=list("y", "week", "doselevel", "N", "nj")  # what variable you need in the model


# Setup Initial Values- Stochastic Components
set.seed(963)
initM0.fun=function(){ list(  
  beta0 = rnorm(N,50.0,10.0), 
  beta1 = rnorm(N,50.0,10.0),
  beta00 = rnorm(1,100.0, 0.00001),
  beta01 = rnorm(1,0.0, 0.0001),
  beta10 = rnorm(1,0.0, 0.0001),
  beta11 = rnorm(1,0.0, 0.0001),
  s.y = runif(1, 0.0, 250.0),  
  s.b0 = runif(1, 0.0, 250.0), 
  s.b1 = runif(1, 0.0, 250.0) 
  ) }

# Run Open Bugs - Parameters according with 'ProdRun' flag
set.seed(2602)
attach(RatGrowth)
RatGrowthM0=bugs(bugM0.dat, initM0.fun, paramsM0, model.file="RatsGrowthM0.txt",
                 n.chains=NChain, n.iter=NSim, n.burnin=Burnin, n.thin=NThin, debug=FALSE)
detach(RatGrowth)

# Get Simulation from OpenBugs
SArrayM0 <-  RatGrowthM0$sims.array   # Data Arrays
vname <- attr(SArrayM0,"dimnames")[3][[1]]  # Variable Names

# Get Summary statistics of parameters of Interest
RNames <- rownames(RatGrowthM0[["summary"]]) # List of parameters
df_SummaryM0 <- data.frame(Parameter = RNames)
df_SummaryM0 <- cbind(df_SummaryM0, as_tibble(RatGrowthM0[["summary"]]))
rownames(df_SummaryM0) <- RNames


# Plot TracePlots * BETA00, BETA01, BETA10, BETA11*

# Sampling 5000 points to generate "thinner" traceplots
set.seed(312)

L <- NSim-Burnin

S <- if (Sz < L) sort(sample(1:L, Sz, replace = FALSE)) else 1:Sz

# Build working dataframe
D_WorkBeta00 <- data.frame(ValCh1=SArrayM0[S,1,paste0("beta00")],
                           ValCh2=SArrayM0[S,2,paste0("beta00")],
                           ValCh3=SArrayM0[S,3,paste0("beta00")])

D_WorkBeta01 <- data.frame(ValCh1=SArrayM0[S,1,paste0("beta01")],
                           ValCh2=SArrayM0[S,2,paste0("beta01")],
                           ValCh3=SArrayM0[S,3,paste0("beta01")])

D_WorkBeta10 <- data.frame(ValCh1=SArrayM0[S,1,paste0("beta10")],
                           ValCh2=SArrayM0[S,2,paste0("beta10")],
                           ValCh3=SArrayM0[S,3,paste0("beta10")])

D_WorkBeta11 <- data.frame(ValCh1=SArrayM0[S,1,paste0("beta11")],
                           ValCh2=SArrayM0[S,2,paste0("beta11")],
                           ValCh3=SArrayM0[S,3,paste0("beta11")])

# Plot Traceplots for selected data-frames
P1 <- D_WorkBeta00 %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta['00'])) +
  theme_bw()
P2 <- D_WorkBeta01 %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta['01'])) +
  theme_bw()
P3 <- D_WorkBeta10 %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta['10'])) +
  theme_bw()
P4 <- D_WorkBeta11 %>%
  ggplot(aes(seq(from=1,to=Sz)))+
  geom_line(aes(y=ValCh1, colour=1), size=0.8)+ 
  geom_line(aes(y=ValCh2, colour=2), size=0.8)+ 
  geom_line(aes(y=ValCh3, colour=3), size=0.8)+ 
  labs(y = expression(beta['11'])) +
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.text.x=element_blank(),
                           axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)

# Remove Working Variable to free memory
remove(D_WorkBeta00, D_WorkBeta01, D_WorkBeta10, D_WorkBeta11 )

# Plot ACF Plots * BETA00, BETA01, BETA10, BETA11*

# Build working dataframe
D_WorkBeta00 <- data.frame(ValCh1=SArrayM0[,1,paste0("beta00")])
D_WorkBeta01 <- data.frame(ValCh1=SArrayM0[,1,paste0("beta01")])
D_WorkBeta10 <- data.frame(ValCh1=SArrayM0[,1,paste0("beta10")])
D_WorkBeta11 <- data.frame(ValCh1=SArrayM0[,1,paste0("beta11")])

# Plot ACF Plots for selected data-frames
P1 <- ggAcf(D_WorkBeta00$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta['00'])) +
  ggtitle(NULL)+
  theme_bw()
P2 <- ggAcf(D_WorkBeta01$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta['01'])) +
  ggtitle(NULL)+
  theme_bw()
P3 <- ggAcf(D_WorkBeta10$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta['10'])) +
  ggtitle(NULL)+
  theme_bw()
P4 <- ggAcf(D_WorkBeta11$ValCh1, lag.max = 100)+
  labs(x = "Lag", y = expression(beta['11'])) +
  ggtitle(NULL)+
  theme_bw()

# Plot all Graphs in a same frame
ggpubr::ggarrange(P1+theme(axis.title.x=element_blank(),
                           legend.position="none"), 
                  P2+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P3+theme(axis.title.x=element_blank(),
                           legend.position="none"),
                  P4+theme(axis.title.x=element_blank(),
                           legend.position="none"), ncol = 2, nrow = 2)
# Remove Working Variable to free memory
remove(D_WorkBeta00, D_WorkBeta01, D_WorkBeta10, D_WorkBeta11 )

# Print statistics of interest - Beta0i and Beta1i
df_Prt <- df_SummaryM0[c(paste0("beta0[",c(1:N),"]"),
                         paste0("beta1[",c(1:N),"]")),c(2:4,6,8)]

df_Prt %>%
  kbl(booktabs = TRUE, digits = 4, longtable = TRUE, 
      caption = "Summary - Beta0i and Beta1i for Rat Growth (Run-0)") %>% 
  kable_styling(latex_options = "striped")

# Print statistics of interest - beta00-beta11
df_Prt <- df_SummaryM0[c("beta00", "beta01", "beta10", "beta11"),c(2:4,6,8)]

df_Prt %>%
  kbl(booktabs = TRUE, digits = 4,
      caption = "Summary - beta00-beta11 for Rat Growth (Run-0)") %>% 
  kable_styling(latex_options = "striped")

# Print statistics of interest - Precisions
df_Prt <- df_SummaryM0[c("tau.w", "tau.b0", "tau.b1"),c(2:4,6,8)]

df_Prt %>%
  kbl(booktabs = TRUE, digits = 4,
      caption = "Summary - Precisions for Rat Growth (Run-0)") %>% 
  kable_styling(latex_options = "striped")

# Create Temporary data-frame
D1_Work <- RatGrowth
colnames(D1_Work) <- c("dose", "IDinDose", "week01","week02","week03","week04","week05",
                         "week06","week07","week08","week09","week10","week11")

P2 <- D1_Work %>% 
  pivot_longer(cols = week01:week11, names_to = "weekStr", values_to = "rweight") %>%
  mutate(weekNo = as.integer(substr(weekStr,5,length(weekStr)-5))) %>% 
  ggplot(aes(group=weekNo))+ 
  geom_boxplot(aes(x=weekStr, y=rweight)) +
  labs(y="Weight (in g)")+
  facet_grid(~dose)+
  theme_bw()
P2 + theme(axis.title.x=element_blank(),
           axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8))
remove(D1_Work)


# Prepare Data-Frame for next steps
D1_Work <- rbind(data.frame(beta00=SArrayM0[,1,paste0("beta00")],
                            beta01=SArrayM0[,1,paste0("beta01")],
                            beta10=SArrayM0[,1,paste0("beta10")],
                            beta11=SArrayM0[,1,paste0("beta11")], Chain=factor(1)),
                 data.frame(beta00=SArrayM0[,2,paste0("beta00")],
                            beta01=SArrayM0[,2,paste0("beta01")],
                            beta10=SArrayM0[,2,paste0("beta10")],
                            beta11=SArrayM0[,2,paste0("beta11")], Chain=factor(2)),
                 data.frame(beta00=SArrayM0[,3,paste0("beta00")],
                            beta01=SArrayM0[,3,paste0("beta01")],
                            beta10=SArrayM0[,3,paste0("beta10")],
                            beta11=SArrayM0[,3,paste0("beta11")], Chain=factor(3)))

# Plot the Graphs of beta00, beta01, beta10, beta11
P1 <- D1_Work %>%
  ggplot(mapping = aes(x = beta00, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(beta['00']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

P2 <- D1_Work %>%
  ggplot(mapping = aes(x = beta01, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(beta['01']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

P3 <- D1_Work %>%
  ggplot(mapping = aes(x = beta10, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(beta['10']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

# Plot the Graphs of Tau
P4 <-D1_Work %>%
  ggplot(mapping = aes(x = beta11, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(beta['11']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

ggpubr::ggarrange(P1, P2, P3, P4, ncol = 2, nrow = 2)

# Remove Working Variable to free memory
remove(D1_Work)

# Prepare Data-Frame for next steps
D2_Work <- rbind(data.frame(tau.w=SArrayM0[,1,paste0("tau.w")],
                            tau.b0=SArrayM0[,1,paste0("tau.b0")],
                            tau.b1=SArrayM0[,1,paste0("tau.b1")], Chain=factor(1)),
                 data.frame(tau.w=SArrayM0[,2,paste0("tau.w")],
                            tau.b0=SArrayM0[,2,paste0("tau.b0")],
                            tau.b1=SArrayM0[,2,paste0("tau.b1")], Chain=factor(2)),
                 data.frame(tau.w=SArrayM0[,3,paste0("tau.w")],
                            tau.b0=SArrayM0[,3,paste0("tau.b0")],
                            tau.b1=SArrayM0[,3,paste0("tau.b1")], Chain=factor(3)))


# Plot the Graphs of TAU_W, TAU_Beta0, TAU_Beta1
P1 <- D2_Work %>%
  ggplot(mapping = aes(x = tau.w, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(tau['w']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

P2 <- D2_Work %>%
  ggplot(mapping = aes(x = tau.b0, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(tau['b0']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

# Plot the Graphs of Tau
P3 <-D2_Work %>%
  ggplot(mapping = aes(x = tau.b1, group = Chain))+
  geom_density(aes(colour=Chain), size=0.5)+
  labs(x = expression(tau['b1']), y = "Density") +
  scale_color_manual(values = cbp2)+
  theme_bw()

ggpubr::ggarrange(P1, P2, P3, ncol = 1, nrow = 3)

# Remove Working Variable to free memory
remove(D2_Work)

```

